---
title: swing算法介绍
date: 2019-04-01
categories:
- 推荐算法
tags:
- swing
---

# 算法整体介绍

## Link Prediction

一般来讲推荐系统的应用有两个前提：一个是信息过载，一个是用户的意图不明确。这两种情形下用户对推荐是有强需求的，好的推荐系统可以帮助用户找到他感兴趣或者对他有用的信息。随着互联网的发展，推荐已经广泛应用在各个领域，尤其是移动互联网的崛起，时间碎片化，用户很多的时间都在手机的各种app上，推荐正在变得越来越重要。

现实世界中的网络大部分都可以抽象为两种，一种是user-user这种同质的网络，比如最常见的社会网络：微信、Facebook等；另一种是user-object，人和物体之间的网络，后者更为广泛，比如：电子商务、音乐、电影、新闻等等很多在线服务都可以抽象成user-object这种bipartite network。推荐在这两种网络中都可以归为link prediction的范畴，给定一个图G(V, E)，V是节点的集合，E是边的集合，推荐其实就是预测图中尚未存在的边。

关于Link Prediction和推荐系统学术界已经有很多研究工作，比如经典的协同过滤-Collaborative Filtering，Adamic/Adar等等。这里推荐几篇经典的论文，想学习基础知识的同学可以参考：

[1] ItemBased Collaborative Filtering Recommendation Algorithms <br> 
    http://files.grouplens.org/papers/www10_sarwar.pdf <br>
[2] Amazon.com recommendations: Item-to-Item Collaborative Filtering  
    http://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf <br>
[3] The Link Prediction Problem for Social Networks <br>
    http://www.cs.cornell.edu/info/people/kleinber/link-pred.pdf

Collaborative Filtering有user-based和item-based两种，user-based多用于挖掘那些有共同兴趣的小团体；而item-based侧重于挖掘item之间的关系，然后根据用户的历史行为来为用户生成推荐列表。相比item-based，user-based方法推荐的新颖性好一些，但是准确性差，item-based 的应用更为广泛。在之后又发展出SVD和一系列model-based方法，在实际的推荐系统中可以分为两层，match层和rank层。match用各种算法做召回，比如CF，Content B-based，Demographic-based等等，做粗排之后交由rank层的model做更精细的排序。

本文主要侧重在基于图结构做match，我们提出了一种新的算法—SWING，相比CF在很多领域和场景都取得了非常显著的提升，说的这么神奇，SWING到底是个什么东西呢，我们来慢慢解析。

## Triangle Rank

说到SWING，首先得从Triangle Rank(也是我们原创的算法)说起，起源是我有一段经历在社会网络中做好友推荐。也就是在上边提到的第一种user-user这种网络中做link prediction，产品形态比如“你可能认识的人”。

好友推荐最重要的就是衡量node proximity，即节点的邻近程度，一个节点和你越“亲近”，那么你认识他的可能性越大。传统度量节点的邻近程度有下面这些方法(细节见上边推荐的第3篇文章)：

![avatar](/images/rec/rec-1.png)

公式看起来有点抽象，我们来看一个具体的例子：在图1中，s是主节点，[a, b, c, d, e, f]是s的好友集合，[r, p, q, w]是s的2-hops邻居节点。假设我们要为s推荐好友，你会怎么做呢？很容易可以想到计算共同好友数(Common Neighbors)，比如q和s有3个共同好友，r和s有2个共同好友，这样推荐的顺序是： q = p > r > w。我们用T(s)来表示节点s的度数，我如果告诉你，T(r)=10，T(q)=300，你觉得这样推荐合理么？这样看似乎先推荐r更合理，于是我们又可以想到Jaccard’s Coefficient或者Cosine Similarity，对本身度数比较大的节点做惩罚，这样就很大程度上解掉了这个问题。

在实际应用中更著名的是Adamic/Adar，常常被各种paper拿来当base line。我们来看一下Adamic/Adar的定义: 

$$ AA_{u,v} = \sum_{z \in \Gamma(u) \bigcap \Gamma(v)} \frac{1}{log(|\Gamma(z)|)} $$

去掉分母的话不就是共同好友数么？是的，Adamic/Adar就是对中间节点(intermediate node)的节点做了一个加权，中间节点的度数越大，它的权重越小。但是实际应用中它的效果却非常好，Facebook在WSDM’11上发表了一篇文章，Supervised Random Walks: Predicting and Recommending Links in Social Networks，用random walk来做link prediction，费了半天劲在最后的评测上只比Adamic/Adar好了一点点，学术意义大于实际意义，当然Facebook线上用的肯定还有其他算法。

概括一下就是，Adamic/Adar很简单，但是却很有效。上边第3篇文章大牛Kleinberg在他们数据集上评测，效果最好的是Adamic/Adar和Katz，Katz算法复杂度太高了，实际很少会直接应用。
 
![avatar](/images/rec/rec-2.png)

我们再观察一下图1的网络结构，还有什么可提升的空间么？你可能已经注意到了，(a, b)，(b, c), (a, c)之间都还有一条边，所有上边提到的算法，都是基于“点”计算节点相似性，并没有考虑中间节点的网络结构。在社会网络发展的研究领域中，有一个著名的理论，就是节点之间都在慢慢的相互之间连成三角形，其实s每加一个二跳节点为好友，都会新构成一个或多个三角形(close a triangle)，比如s如果和w新建立了好友关系，[s, e, w]就构成了一个三角形，三角形在网络中是非常稳固的结构。

我们提出了一种新的算法Triangle Rank，定义如下，U(s)表示节点s所有二跳节点候选集：

$$ TR_{s,u} = \sum_{i \in \Gamma(s) \bigcap \Gamma(u)} \sum_{j \in \Gamma(s) \bigcap \Gamma(u)} \frac{Trg(i,j,u)}{1 + \sum_{k \in U(s)} Trg(i,j,k)} $$

$$ Trg(i,j,u) = \left\{
\begin{array}{rcl}
1       &      & {if (i,j,u) form \quad a \quad triangle}\\
0       &      & {else}
\end{array} \right. 
$$

直观来理解Triangle Rank就是它不再以“点”向二跳拓展，而是以“边”向外拓展。同时中间的节点如果越“活越”(构成的三角形越多)，则权重越低。和Adamic/Adar相比，Triangle Rank要更严格，它考虑了中间节点的网络结构，算出来的节点和主节点连接更紧密，准确性也就越高。

仍然以图1为例，我们来计算Triangle Rank的分数：<br> 
  TR(s, p) = 1/2 + 1/1 + 1/1 = 2.5 <br> 
  TR(s, r) = 1/2 = 0.5; <br> 
  TR(s, q) = TR(s, w) = 0;
  
实际用的时候分母可以加1平滑，这里没加。对于不构成三角形的节点可以用Adamic/Adar补足，这样推荐的顺序是：p > r > q > w。

Triangle Rank在好友推荐的实际线上应用中，加好友数同比传统的方法增长40%以上，非常有效。至于怎么数网络中的三角形个数，留给大家想一想:)，它的核心代码只有30行。

## swing

对于上边提到的第2种网络，user-object这种网络是如何做推荐的呢，在淘宝中的推荐就是属于user-object这种二部图。用的比较多的方法就是著名的Collaborative Filtering了，以及其各种改进版本。Item-based CF的核心仍然在于计算item节点之间的proximity。                                                                                                 
阿里集团的eTREC，高效实现了item-based CF，可以支持用户自定义相似度，非常方便，是快速搭建一个推荐系统的利器。eTREC中非常重要一个贡献就是一种item之间相似度的计算方式WB-Cosine，定义为：

![avatar](/images/rec/rec-4.png)

这个算法在经典余弦相识度算法基础上，对那些行为多的用户进行权重惩罚，同时还考虑了时间因素，实际应用效果比Jaccard’s Coefficients和原始的Cosine Similarity会有提升。

如果有同学自己写代码实现过CF，人工review过CF的结果，就会发现CF除了大家都知道的冷启动问题，还有几个其他的问题。比如它抗噪音能力差，算出来结果中会有一些看起来不太准的case或者badcase，所以在实际用的时候还会借助一些其他的信息，比如商品类目。另外一个问题就是“哈里波特”问题，不知道的同学可以查一查，“哈里波特”问题并没有表面看起那么容易解决，直接通用调整分母模上的指数来进一步惩罚热门的item，往往会带来其他的问题，比如precision会下降，这里不进一步展开，感兴趣的同学可以私下交流。

对于user-user这种网络，计算完节点亲密度的同时就可以直接生成推荐结果了；而user-object中的推荐分为两步，以item-based CF为例，先计算item-item之间的相似度(我们称为i2i)，然后根据用户有过历史行为的item集合来为其生成推荐结果。另一个不同是它是一个二部图，在计算i2i的时候，中间的节点相互之间是没有边的。

仍然先直观的来看一个例子，如图2所示，user集合为[a, b, c, d, e]，item集合为[s, r, p, q, w, z, t, x]；主宝贝是s，我们要计算和s相似的item，这个图从结构上看和图1基本是一样的，只不过左右红色和橙色的节点变成了item，中间蓝色的节点是user，但是user节点相互之间是没有边的。我们上边提到的所有基于“点”的相似度算法，就都可以用上了，比如最常用的Jaccard’s Coefficient和Cosine Similarity，还有eTREC中的WB-Cosine。

![avatar](/images/rec/rec-3.png)

我们观察一下图2，在二部图中是没有三角形的(中间user和user之间没有边的概念)，我曾经有一段时间困惑在如何对二部图中user之间建模，即：user之间如何定义边，这样就可以直接利用Triangle Rank了。但其实在user-object这种图里，不用管中间的user之间有没有边，两个user是好友则建立一条边么？这个信息其实是没有意义的，或者说是不相关的。

图中没有了三角形，但是仍然会构成很多“秋千”状的swing角形结构，比如：(a, r, b)构成一个swing，(b, p, c)也构成一个swing，这种角形结构仍然是一种强信息，从网络结构上要比(e, w)这种单拎出来的一条边“稳固”的多。如果多个user在点击了s的同时，都只共同点了某一个其他的item，那么这个item和s一定是强关联的，同时借鉴Adamic/Adar的思想，如果两个user pair对之间构成的swing结构越多，则每个结构越弱，在这个pair对上每个节点分到的权重越低。偶然之中有必然，大家可以仔细想一想，很巧妙。对于那些没有构成swing结构的节点(Common Neighbors=1)，其实关联性是很弱的，只有1个user有过行为，如果要尽可能的扩大召回，可以计算Adamic/Adar补足。

我们给出swing的形式化定义：

$$ s(i, j) = \sum_{u \in U_i \bigcap U_j} \sum_{v \in U_i \bigcap U_j} \frac {1}{\alpha + |I_u \bigcap I_v|} $$

Ui表示点击过i的user集合， Iu表示u点击过的item集合。所有传统的node proximity度量方式(random walk等传播算法除外)都是以“点”的方式向二跳节点扩展去计算，而Triangle Rank和SWING都是以某种更“稳固”的网络结构向二跳节点扩展。和Collaborative Filtering比，swing要更严格，它更好的利用了人的collective intelligence，去噪能力强，每一个swing结构都是“有益”的信息，CF不是，CF中很多节点都可能是不相关的“噪声”，而且没有办法区分。

SWING另外一个优点是它对网络结构的变化相对更灵敏，如果出现一个新的很相关的item，如果有部分用户都发现了这个item并且都点了它，那么它就很可能排上去(这个优点在user-user网络里会更突出)。在实际用的时候，我们也发现SWING的这个特性会带来一些困扰，比如一些稍显“色情”的图片，很多用户都去点，那么它就有可能被排到前面，不过总体还好，也有解决方法，这里就不展开了。

同样，我们可以对“活跃”的user进行惩罚，增加IUF(inverse user frequency)因子，评测表明可以进一步提高precision。                                     

## 算法复杂度及实现

假设网络中item的总数量是T，item的平均节点度数是N，user的平均节点度数是M，那么item-based CF的算法复杂度为O(T*N*M)，SWING的算法复杂度是O(T*N^2*M)。

eTREC中高效实现了CF，并将整个流程简化为两轮map-reduce，原始的SWING只需要一轮map-reduce。如果添加IIF因子，需要在处理基础数据的时候额外加1~2轮map-reduce。  

# swing算法应用

视频推荐技术中，常常会使用基于视频的协同过滤（Item-based Collaborative Filtering）方法，但是Item-based CF的核心在于计算视频与视频之间的相似度。这种i2i（item-to-item）问题，最常用的方法就是计算它们之间的余弦相似度。如表 1，根据用户的观看记录（1代表看了视频，0代表没看视频），可以计算两个视频在用户维度上的余弦相似度来获得视频之间的相似度关系。通过计算可以得到Sim(Video1, Video3)=Sim(Video1, Video4)=0.77。

![avatar](/images/rec/rec-6.png)

同样的，由于Swing算法也是基于图结构的算法，通过用户行为的信息，可以构造出user-object的二部图，从而应用上Swing算法。

## Swing算法在视频推荐中的问题

通过对swing结果的仔细分析，发现swing推荐出来的结果存在一些badcase，比如图 2的推荐结果中除了“龙珠”系列的动画视频，还有“我的世界”、“海贼王”、“王者荣耀”、“一拳超人”等不太合理的推荐结果。这些不太合理的推荐视频，在swing中得分靠前。这种现象多出现在曝光度是中低频的视频的推荐结果中。

我们对源数据、用户行为等进行了比较详细的分析，发现这个问题的原因是：swing算法对于视频的同时被看的用户数量过少的情况，并不适用。从统计学的角度来看，数据量过少，往往会导致结果的误差过大。也就是说当两个视频的同时被看的用户数量过少时，这时候swing计算得出的结果误差会比较大。

举个极端的例子：

![avatar](/images/rec/rec-5.png)

如图 3所示，有A、B、C三个视频，X1到X10共10个皇马死忠球迷，只关注音乐的音乐爱好者Y。皇马死忠球迷会看与皇马相关的内容，不管是热门视频C，还是中低频视频A，他们都会观看，可以假定他们都看了200个关于皇马的视频。其中有一个球迷X1，被其他朋友推荐了一首冷门音乐B，听完发现不喜欢这种暗黑系古典音乐，还是喜欢比较激昂的皇马队歌A。音乐爱好者Y会听各种音乐，不管是A，还是B，都会播放。那么在这种情况下，由于视频A、B的共现用户量过少（只有2个），从而导致swing算法得出的分数s(A, B)=0.33>s(A, C)=0.22。但是很明显，用户在观看视频A的时候，推荐视频C比推荐视频B要好。

### 解决方法

问题是由两个视频的同时被看的用户数量过少导致的，所以我们需要根据同时观看过两个视频的用户数量来对结果进行处理。我们在swing的基础上，往其公式中增加了指示函数，形成swing5的算法。

$$ s(i, j) = \sum_{u \in U_i \bigcap U_j} \sum_{v \in U_i \bigcap U_j} \frac {1}{\alpha + |I_u \bigcap I_v|} * I(|U_i \bigcap U_j|) $$

$$ I(x) = \left\{
\begin{array}{rcl}
1       &      & {x \ge 5}\\
0       &      & {x \leq 5}
\end{array} \right. 
$$
