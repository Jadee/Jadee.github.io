---
title: RecSys2019总结
date: 2019-10-17
categories:
- 推荐算法
tags:
- swing
---

# RecSys2019概况

会议涵盖了和推荐系统相关的非常广泛的主题。参与其中，我们除了能看到各种有意思的技术、算法的研究和应用，也看到越来越多的参与者意识到并致力于解决推荐系统的社会责任问题。在当今的时代，推荐系统已经无处不在，从方方面面影响着人们如何获取信息，如何消费，如何娱乐，所以"如何建立对社会负责的推荐系统"这样的问题在今天就尤其值得关注(Panel讨论的主题)。两个Keynote也都在强调推荐系统的社会影响。 第一个Keynote演讲人Mireille Hildebrandt谈到了GDPR，她指出GDPR通过限制用户定向能防止推荐系统算法一味地逐利。 第二个Keynote演讲者Eszter Hargittai谈到了人们的在线行为在不同平台之间的差异以及这些差异如何导致算法出现偏差。

<!-- more -->

主会采用了单track的形式，包括以下几个Paper session。

1) Ranking and Deep Learning in Recommenders  
2) User Side of Recommender Systems  
3) Deep Learning for Recommender Systems  
4) Recommendations in Advertising, Promotions, Intent and Search  
5) Applications of Recommenders in Personal Needs  
6) Algorithms: Large-Scale, Constraints and Evaluation  
7) Using Side-Information and User Attributes and Cold-Start in Recommender Algorithms

值得一提的是今年的最佳论文给了一篇争议较大的论文，其挑战了近年推荐领域深度模型效果的可复现性。

# 论文简介

**SESSION: Ranking and deep learning in recommenders**

## Personalized Re-ranking for Recommendation

应用场景是淘系商品推荐的重排(re-ranking), 希望克服只根据ctr排序导致的用户点击效果可能非最优的问题。按照个人理解，如果一个用户近期兴趣是电子产品，长期兴趣是美食，ctr排序可能出现电子产品跟美食交替排列的情况，浏览的时候会让人出现信息过载的问题。reranking问题在图像领域研究也较多，比如person Re-identification。

作者在建模item相互之间的影响的时候，没有考虑RNN类的网络，主要是对长距离建模能力较弱， 而是通过NLP中常用的transformer来实现的，而transformer的multi-head self-attention的目标就是为了让相互相似的排列更加集中一些，具体来说，如果一部分item比较相似，由于任意一个item跟相似的item的attention权重较大，那self-attention加权后的特征会更加靠近这些互相相似样本的均值附近，也就是这些特征都比较相似，所以输出的排序位置也较相似。transformer的输入包括item特征、预训练模型的user-item的嵌入特征(softmax前一层)以及ranking model输出的位置信息的嵌入特征（位置特征加在前面两类特征拼接后的特征上），而输出是一个线性层+softmax得到每个位置的重排score，重排score和点击标签用来计算损失函数。

在item丰富且具有语义的场景中，用户兴趣差不多的样本很多，重排收益可能会较大，如果item较少且为非标准化的内容，可能不需要考虑重排。另外多item下的self-attention计算成本也较高（作者采用了4层transformer*3个head），在不降低效果的前提下，高效率网络也值得探索下（比如是否可以采用矩阵分解和简单神经网络结合的方法）。

非常清晰明了的网络结构图

![avatar](/images/rec/rec-14.png)

## Online Ranking Combination

这篇paper的框架如下图，考虑一个实时推荐系统依赖了几个base ranker，需要有一个combiner对不同ranker的排序结果进行重新混排，论文提出的算法能够直接优化ranking function，实时更新每个ranker的对应权重来匹配环境的变化以及用户实时偏好的转移。

![avatar](/images/rec/rec-15.png)

常规的做法是定义一个替代函数(surrogate function), 例如取label与各个base ranker加权和的loss，利用梯度下降的方式来做优化。论文中的观点是优化替代函数不等同与优化rank函数。

为了能够直接优化rank function，论文提出了两种方式，一种是指数加权算法(EXPONENTIALLY WEIGHTED ALGORITHMS)，一种是。

### EWA

指数加权的思想是，限定一个参数空间，通过全局搜索的方式，对每组参数都直接评估rank表现(例如NDCG)并记为r，每次选择某一组参数结果的概率为其reward的指数加权结果，论文对这个公式的理论保证进行了讨论，它work的前提是reward加和表达足够平滑且参数空间足够大。它有一个弊端是，所需要的参数空间size随着#ranker的增加而指数增加，所以扩展性并不好。

![avatar](/images/rec/rec-16.png)

### SPSA以及RSPSA

论文中介绍了两种基于梯度的算法，同时扰动随机近似(SPSA)以及其结合弹性传播的变体RSPSA。

rank 函数的累计reward是一个阶跃函数，所以在SPSA中，扰动的size对梯度收敛影响很大：如果size过小会停滞在某一个区域无法找到正确方向，如果过大可能导致越过局部最优点。而RSPSA引入了弹性传播：梯度的step size 会和梯度方向的变化相关，如果梯度方向变化，则减小step size否则增加step size，从而避免了上述SPSA的问题。

![avatar](/images/rec/rec-17.png)

### RFDSA+

作者提到，他们通过观察RSPSA的优化过程找到了一些优化点：reward function是比较平坦的区域，近似得到的梯度方向会经常发生变化，是的step size减小，但这个时候其实需要算法有一个足够大的扰动来越过平坦区域。

论文提出的RFDSA+其实是 RSPSA 去掉同时扰动、加上有限差分、加上0梯度检测。每次只关注一个参数，如果发现这个参数上的梯度为0，则增加扰动的size以越过平坦区域。虽然改动看起来比较简单，但从实验结果来看效果不错

![avatar](/images/rec/rec-18.png)

## A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation

本文是best paper候选之一。推荐问题中常常面临多目标优化，比如CTR、GMV、停留时长等，这些目标常常是相关和矛盾并存。例如单一优化CTR的模型，CTR效果通常会比CTR和GMV共同优化的模型高。帕累托优化（Pareto-Efficient，PE）在这个场景下是指模型附近（locally）不存在另一个模型，使得A目标提高且不损害其他任何目标。本文提出一种PE的交替迭代框架，可以求解PE局部最优模型。

**方法**

定义模型

$$ L(\theta) = \sum_{i = 1}^K w_i * L_i(\theta) \quad \quad s.t. \quad \sum_{i = 1}^K w_i = 1 and w_i \geq c_i $$

其中：  
$L_i$：是目标i的loss  
$w_i$：代表相应权重

根据前人工作，可知帕累托驻点（stationary point）条件是：  

$$ \sum_{i = 1}^K w_i = 1，\forall \quad w_i \geq c_i \quad and \quad \sum_{i = 1}^K w_i * \nabla_{\theta} L_i(\theta) = 0 $$ 

则我们可以近似优化

$$ min || sum_{i = 1}^K w_i * \nabla_{\theta} L_i(\theta) ||^2 \quad s.t. \quad \sum_{i = 1}^K w_i = 1 and w_i \geq c_i $$ 

进而得到算法

![avatar](/images/rec/rec-19.png)

算法思路很简单，一次对 $\theta$ 梯度下降，一次求解 $w$ 的closed form。

**结果**

电商场景的离线和在线结果均有报告，PE-LTR算法能够比较自由地平衡CTR和GMV，即CTR接近专门优化CTR的算法同时GMV超出比较多，反之亦然。

![avatar](/images/rec/rec-20.png)

**思考**

本文是不同于加权平均和约束优化的另一种处理多目标问题的办法，三者简单比较如下

加权平均非常直观，但权重的物理意义不明显，通常只能拍。优势在于对优化方法无特殊要求，大部分算法可以直接套用；  
约束优化比较直观反应商业诉求，实际难点在于优化成本比较高，可能需要case by case设计高效算法；  
本文的PE方法跟加权平均相似，容易实现，也比加权平均得到更多信息。如何优化计算PE边沿是个有趣的课题（基于线性或者MAB一类的简单模型）。

## From Preference into Decision Making: Modeling User Interactions in Recommender Systems

虽然是一篇short paper，内容短小精悍却蛮有意思，作者也被邀请在recsys大会第一天做了presentation。

论文首先抛出了几个问题：我们不希望推荐系统的反馈延迟过大，例如一天中的N次浏览，所推荐的内容完全一致，另一方面也不希望推荐系统过于敏感，例如对页面中的itemA和B感兴趣，先点击了A，当回退到页面时所有推荐内容都和A相关，B却消失了。

![avatar](/images/rec/rec-21.png)

所以作者想解决的问题是：如何对用户的各种行为做联合建模？

* 时序行为：例如搜索、浏览、筛选等发生在不同页面的行为  
* 正反馈：例如点击、消费、收藏等同一页面的行为  
* 负反馈：例如skip, 忽略或者点击不喜欢等同一页面的行为  
和主流的通过用户行为直接对正负label做建模不同，论文希望去更多的讨论用户做feedback之前的micro-level的决策过程。

![avatar](/images/rec/rec-22.png)

作者从决策场理论(DFT)中得到一些灵感，图中ABC代表三个选择，m代表特征，论文认为"偏好是micro-level决策过程的结果"。

下图是论文提出的网络结构：PL-RNN (page level rnn)：

![avatar](/images/rec/rec-23.png)

其中input的每个embedding不是来自于某一个有行为的item，而是来自于一整个页面(包括了所有正负反馈的建模)，如下图：

![avatar](/images/rec/rec-24.png)

输出层则对每一个item的结果都进行了预测，从作者给出的测试数据看，PL-RNN不仅好于传统模型如SVD++，也好于RNN模型。另外作者还针对不同的负样本采样做了一个测试，测试表明softmax和logistic建模对负例的选择非常敏感，但是pairwise模型则更稳定。

## Recommending What Video to Watch Next: A Multitask Ranking System

本文背景是要解决如下真实生产环境中的问题：

* 有很多不同甚至是冲突的优化目标，比如我们不仅希望用户观看，还希望用户能给出高评价并分享。  
* 系统中经常有一些隐性偏见。比如用户是因为视频排得靠前而点击&观看，而非用户确实很喜欢。因此用之前模型产生的数据会引发bias，从而形成一个反馈循环，越来越偏。如何高效有力地去解决还是个尚未解决的问题。

多目标一般分为两类：

* engagement objectives：点击以及于视频观看等参与度目标  
* satisfaction objectives：Youtube上的喜欢某个视频、打分

对于存在潜在冲突的目标，通过MMOE的结构来解决，通过门结构来选择性的从输入获取信息。如下图，本文提出了一个Deep&Wide + Multi-gate Mixture-of-Experts (MMOE)的架构，MMOE出自google的另一篇解决multitask的论文，主要适用于目标不是那么一致的多目标优化场景。此外文章为了解决selection bias还引入了个shadow tower，据作者说线上效果还不错。

为了减少selection bias（比如position bias），用图中左边的浅层塔，接收selection bias作为输入，比如排序位置，输出标量作为主模型最终预测的偏差项。 模型将目标分解为两部分，一个是无偏的用户偏好，另一个是倾向分。模型结构可以看做是Wide&Deep的扩展，浅层塔代替Wide部分。因为直接学习shallow tower,所以不用随机实验区获得倾向分。

![avatar](/images/rec/rec-25.png)

**SESSION: User side of recommender systems**

## Users in the Loop: A Psychologically-Informed Approach to Similar Item Retrieval

本次Recsys有不少来自于时尚界的公司的研究和应用文章。TrueFit是一家美国的时尚初创公司，希望通过算法匹配帮助消费者在网上买到尺码合适的衣服和鞋子。TrueFit的这篇文章介绍了一个非常有意思的研究工作——在时尚界如何度量item之间的相似性，这项工作更像是一篇心理学研究。文章获得最佳论文提名。

这项工作有两个目标：

1) 建立一种合理的方法论框架来评估用户对item相似性的判断。为了实现这一目标，作者精心设计了许多相似性判断任务通过在线问卷发放给用户，并通过多种意图理解检查、效果过滤流程，消除了低质量的回答。这些细致的质量保证程序在心理学研究中都很常见，但是它们很少被用作机器学习研究的一部分而进行的用户研究。

2) 假设检验：心理上的Tversky相似性比标准相似度函数能更好地捕捉用户的行为。  
这个所谓的Tversky相似度如下所示

$$ S_T(a，b) = \theta * f(A \bigcap B) - \alpha * (A - B) - \beta(B - A) $$

其中，A是item a的特征集合，B是item b的特征集合，$A \bigcap B$ 表示a和b共有的特征，$A − B$ 是a独特的特征，$B − A$ 是b独特的特征。这三项的权重分别为$\theta，\alpha，\beta$。

作者通过实验证明了用户的行为违反了常用数学相似性指标的属性和假设。时尚商品的某些特征比其他特征更为重要，用户的相似性判断是不对称的，并且item的共同特征比独特特征更重要。abtest实验证明，Tversky相似性相对于Jaccard相似性，是统计上显著更优的item相似度建模。具体的实验数据不再罗列，个人觉得这篇文章以用户真实需求为导向的方法论值得学习，这可能也是其被提名为最佳论文的原因。

**SESSION: Deep learning for recommender systems**

## Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches

本文获得RecSys2019 best paper award
过去若干年，基于深度神经网络（DNN）的算法在多个领域（含推荐系统）取得突破性进展。这些研究工作的高速发表，让大家比较难认定当前最佳(state-of-the-art)的算法，同时也有文献指出部分论文的可复现性存在隐忧。Dacrema等研究人员以大家最关心的推荐子课题top-n ranking入手，从可复现性和效果提升两个维度分析过去几年最新的DNN类算法是否取得了让人鼓舞的进展。

* Reproducibility: To what extent is recent research in the area reproducible (with reasonable effort)？  
* Progress:To what extent are recent algorithms actually leading to better performance results when compared to rela-tively simple, but well-tuned, baseline methods？

**方法**

1. 论文收集  
  * 挑选基于DNN的top n ranking算法  
  * 2015年-2018年发表于KDD（4篇）、RecSys（7篇）、SIGIR（3篇）和WWW（4篇）  
  * 如果代码和数据不公开，则email相关作者等待30天回复  
2. Baseline，非DNN based方法  
  * TopPopular：热度优先，非个性化方法  
  * ItemKNN、UserKNN：经典CF加一个相似度控制参数  
  * ItemKNN-CBF：同上，用feature做相似度评估（非user评分）  
  * ItemKNN-CFCBF：混合两种的CF  
  * $P^3 \alpha 和 RP^3 \beta$：两种简单的图随机游走算法  
3. 对于可复现的每篇论文，作以下对比  
  * 与原文一致的训练、调参和预测代码，参数也保持一致  
  * 评估代码被剥离出来，同样用于baseline的评估  
  * 本文所有代码在git上可查阅和下载

**结果**

* 是否可复现

  * 评价标准  
    * 代码经过少量修改可以顺利运行。对于仅提供大框架代码，无法顺利复现的代码，本文认为是不可用的；  
    * 论文中至少有一个数据集是容易获得的；  
  * 统计结果  
    * KDD 3/4(75%)，RecSys1/7（14%），SIGIR 1/3（30%）和 WWW 2/4（50%）  
    * 总体 7/18（39%）  
    * 由于样本太少，不适合得到结论某个会议的论文更容易复现  
    * 复现率逐年有提高

* top-k ranking性能

作者让7篇论文分别对比简单的baseline，摘录如下

1. Collaborative Memory Networks (CMN)：3个数据集CMN都不是最好的“CMN is in no single case the best-performing method on any of the datasets. ”；  
2. Metapath based Context for RECommendation (MCRec)：在唯一的数据集Movie- Lens100k上，Item-KNN显著好于MCRec。同时作者指出MCRec原文代码针对test set的取最高精度，不是恰当的调参结果；  
3. Collaborative Variational Autoencoder (CVAE)：多数case下，baseline方法比 CVAE好。CVAE was only favorable over the baselines in certain configurations and at comparably long and rather uncommon recommendation cutoff thresholds.  
4. Collaborative Deep Learning (CDL): 这篇文章在CVAE前，基本比CVAE弱，比baseline差距更大；  
5. Neural Collaborative Filtering (NCF)：在数据集Pinterest，有两个baseline比NCF好；在MovieLens，NCF明显优于各baseline。为此作者添加了一个额外的线性方法SLIM，结果SLIM优于NCF（暗示deep可能并不需要）；  
6. Spectral Collaborative Filtering (SCF)：在三个数据集的随机切分中，SCF性能垫底。在MovieLen按SCF原文的训练集和测试集划分，SCF效果远超baseline方法。本文觉得这个划分可能有问题，并画图示意。  
7. Variational Autoencoders for Collaborative Filtering (Mult-VAE)：该方法在所有case中均超过baseline方法比较多。本文作者进而加入了SLIM和WMF作为比较，发现差距有所缩小，并在部分评价指标下，非DNN based方法可以取得微弱优势；

**讨论**

* 本文观点  
  * 难复现的主要因素：尽管越来越多作者提供核心代码，但是调参、数据划分等外围代码则常欠奉；方法复杂，机器资源要求高也是难复现的原因；  
  * 效果不如原文的主要因素包括：baseline选择不恰当，比如选择很弱的dnn方法；baseline没有合理调参；缺乏权威且足够新的数据集，导致文献容易选取对自己有利的数据；评估指标比较乱，Precision, Recall, Mean Average Precision, NDCG, MRR等，外加不同的划分方法，top N的N选择等；
  
* 外部讨论  
  * 本文观点比较激进，引起外部大量讨论。总体而言，大家认同推荐系统领域客观上存在评估混乱，浑水摸鱼的文章比较多；另一方面客观上推荐系统在工业届落地特别case by case，研究人员容易跟业界脱节；部分研究者也认为本文作者实验也不够严谨，存在可诟病的地方。详细可以参考: https://www.zhihu.com/question/336304380/answer/766527822
  
## Relaxed Softmax for PU Learning

数字营销公司Criteo在本次Recsys主会贡献了两篇论文，并且参与组织REVEAL workshop。这篇Relaxed Softmax for PU Learning是正会论文的其中一篇，提出一种新的负采样方法，获得最佳论文的提名。

**解决的问题**

在这篇论文中，作者指出当前广泛使用softmax loss和负采样策略用在PU Learning场景的一些缺点。

这篇文章。负采样是PU Learning任务中非常常见的步骤（推荐模型从隐式反馈中学习也可以看作是此类任务）。大部分的方法都采用从某个固定分布中采样的负样本（基于item热度的分布、均匀分布等）。这篇文章提出一种基于Boltzmann分布的负采样策略，采样更靠近算法分类面、信息量更大的负样本。

![avatar](/images/rec/rec-26.png)

**方法**

对比上图中MLE的Loss，作者提出使用Context dependent的分布 $Q_i$ 做负采样

![avatar](/images/rec/rec-27.png)

从active learning和PU learning相关的文献中得到启发，负采样策略对模型的效果会有很大的影响。理想情况下，我们应该采样那些模型错误分类的样本。因此，一个好的负采样分布不仅应该考虑数据样本生成分布P，而且应该考虑当前模型估计的似然G，抽样分布如下所示

![avatar](/images/rec/rec-28.png)

直观理解，这个采样策略会倾向于采样评分模型 $G^{\theta}(i，j)$ 高估的样本，倾向于采样那些更可能在context之下出现的样本(D为样本生成分布)。temperature T是用来矫正采样分布。temperature越小，采样策略更关注分类面附近的样本，explore更少。

**效果**

作者的构造数据实验和公开数据实验都体现出，Relaxed Softmax采样相对于普通的softmax来说训练的模型效果提升明显。

**遗留的问题**

没有启发式的方法来选择temperature，作者在实验中是线性搜索。通常在非构造数据上也不容易得到生成样本的分布D，因此在作者在公开数据上的实验是使用item热度的分布。

**SESSION: Recommendation in advertising, promotions, intent and search**

## LORE - A Large-Scale offer Recommendation Engine with Eligibility and Capacity Constraints

* 内容介绍：

提供优惠或产品折扣等在当今社会的商业行为中非常普遍，这样既能促进销售，也能增加新产品的接受度，与用户有更多的互动。很多企业会设计多种促销方式给不同的用户。以Uber为例，对某些用户提供9折优惠，对其他用户则提供5元的红包。这篇文章提出一些针对这些问题的解决方案，能够以最佳的方式提供促销，达到最大限度的提高用户转化率的目的，同时具备限制用户和商品范围的能力（有资格和库存的要求）。本文提出的方案是Min-Cost Flow network optimization，可以在Polynomial time内完成求解。并提出了两种方案可以适用不同的情况，分别是single period solution和sequential time period offering。同时，文章还讨论了三种在可能影响约束优化在线性能的实际问题：capacity determination、traffic arrival pattern和大规模设置的聚类。

* 详细介绍：

问题说明：offer allocation problem，右侧是不同的客户，左侧是不同类型的offer，其中ci是对人的容量，bj是offer预算，是问题的两个主要约束。

![avatar](/images/rec/rec-29.png)

针对上述问题，现有的解决方案有如下两种:

1) Greedy approaches，这种方式比较常见，对offer建模排序，并结合库存限制要求给出局部最优的结果。  
2) Bandits for constrained online resource allocation，一般方式是在约束范围内通过bandit的方式决策，其他以小概率采用greedy approaches。

![avatar](/images/rec/rec-30.png)

这里将上述问题建模为约束优化问题，如下图：

![avatar](/images/rec/rec-31.png)

建模目标是最大化 $u_i$ 在提供 $O_j$ 的转化概率，F是历史features。$C_i$ 和 $b_i$ 分别是人群和预算的约束。

文章提供了两种算法方案：Single period Solution和sequential time period offering。并证明了integrality gap在这两种情况下都是0，且relax 线性规划的解是integral。

因为constraint matrix是unimodular（元素取值为0|1）,可以转化为LP问题。上面的建模目标可以转化为min cost flow，可以通过Network simplex algorithm解决。下面是一个min Cost Flow的例子，$v_i$是人，ABC是offer。

![avatar](/images/rec/rec-32.png)

具体如下：

![avatar](/images/rec/rec-33.png)

Sequential time Period offering与single period类似，是其在时间上的扩展。区别在于扩展到下一个行为。具体如下：

![avatar](/images/rec/rec-34.png)

其中 $X_{i,j,k}$ 的含义是对用户 $U_i$ 第一个时间发了 $O_j$，第二个时间是否发$O_k$. 第二项的p是其转化概率。文中证明了这种序列的offering同样适用LP。不过不建议超过3个时间段。

* 实验说明

在实验阶段，文章选的数据是email campaign dataset，将数据等分为三份，1）ME（receive men’s merchandise）;2)WE(receive women’s merchandise);3)not receive(NE)。文章实验4中策略，评估指标为：DM（direct method），DR (doubly robust estimator ) ,IPS(inverse propensity score),SnIPS(Self Normalizing IPS ).具体结果如下：

![avatar](/images/rec/rec-35.png)

* 总结  
本文主要基于min cost flow来解决有约束的offer推荐问题。从离线评估看，本文提供的方案要优于greedy approach的方式。后续将在尝试clustering和inline optimization对文中的算法继续探索。

## FiBiNET: Combining Feature Importance and Bilinear feature Interaction for Click-Through Rate Prediction

这篇文章本来也被邀请在第二天给presentation, 但是几位作者缺席。(交叉)特征重要性的学习一直是CTR领域很核心的一个问题，例如FM以及对应的变体，DCN等等很多工作都是解决这个问题的不同思路。

作者的切入点是，用点击或者内机表征特征交叉不足以有效学习，所以结合了一下BIlinear和senet，虽然论文中并没有给出充足的理论证明，但是实现简单，且离线验证效果不错，所以再我们的场景也都值得一试。

![avatar](/images/rec/rec-36.png)

网络结构由这么几项组成：输入层，embedding layer, Senet layer，Bilinear-Interaction layer, combination layer, FC和输出层。

* Sparse Input and Embedding layer  
这一层没什么改动，与常规的DFM/AFM等网络结构一致，将原始稀疏特征映射成低维dense特征。

* SENET Layer  
与AFM等网络结构中对交叉特征的权重进行学习不同，SENET是去学习单特征权重，如下图所示。

SENET分成三个部分：  
  * Squeeze：采用pooling的思路对emb特征进行处理，经验而谈，在CTR问题中选择mean pooling效果较好  
  * Excitation：使用一个两层的全连接对上一步的结果进行变换，会有超参来控制这一步骤的网络参数。  
  * Re-Weight：这一步和attention思路类似，将原始特征乘以前面两步学习到的特征系数。

![avatar](/images/rec/rec-37.png)

* Bilinear-Interaction Layer

与常用的内机、点乘方式来表征特征交叉不同，论文使用了Bilinear的方式，公式如图，先用一个矩阵W对特征i做变换，变换结果再和特征j进行点乘(论文中并没有从理论上对为什么这么操作做过多分析)

![avatar](/images/rec/rec-38.png)

剩余结构

包括拼接、MLP以及输出层并没有太多不同，这里略过

整体来看论文做了网络结构的调优，从离线数据集上看效果不错，实现也很简单值得一试，只是作者没有从理论上给与足够信服的讨论

## Addressing Delayed Feedback for Continuous Training with Neural Networks in CTR prediction

应用于广告展示的推荐系统面临的一个重要难点是，由于季节性、广告活动的变化和其他因素，广告特征分布和点击率（click through rate，CTR）会随着时间而发生巨大的变化。解决这一问题的主要策略是不断地基于新数据连续训练预测模型。然而一些应用场景中数据标签仅存在一段时间且会出现一定的随机延迟，这些延迟的反馈标签对连续训练中的数据新鲜度提出了挑战：新数据在被训练算法接收时可能没有完整的标签信息。一个简单的解决这个问题的方案是除非用户给数据打正标签，否则任何一个数据点都是一个负样本。这种方案往往带来较低的 CTR，从而导致用户体验差和性能差。

本文的重点是找到推荐系统中损失函数和深度学习模型的最佳组合，使其在存在标签延迟反馈的情况下，能够从连续数据流中进行有效的大规模学习。本文考虑两种模型：一是简单 Logistic 回归模型，该模型应用简单、性能良好以及易于接收和处理在线训练的新训练样本，在展示广告中得到了广泛的应用。二是广度-深度（wide-deep）模型，该模型能够有效解决推荐系统的特征复杂性和多样性问题。此外，本文考虑五种损失函数：对数损失、假阴性（fake negative，FN）加权损失、FN 校准、正未标记损失和延迟反馈损失。

本文是首次使用深度学习模型来评估展示广告中的概率 CTR（pCTR），同时解决数据标签延迟反馈问题。考虑到由于时间成本较高，深度神经网络很难在在线训练中应用，本文在不增加工程成本的情况下，对延迟反馈问题进行基准测试并提出时间成本可行的解决方案。

**SESSION: Application of recommenders in personal needs**

## Collective Embedding for Neural Context-Aware Recommender Systems

简介： 本文介绍了如何在推荐系统中考虑上下文的信息，特别是如何加入时间维度的信息，其基本假设是人的兴趣偏好是会随着时间改变的、同时在较短时间里又不会发生较大的改变，然而目前的方法又无法很好的刻画这种特殊的性质，为了解决这个问题，本文提出了上下文感知的神经网络推荐算法，该方法将用户一个时间节点内的所有items集合来对用户建模，同样的将一个时间节点内的所有user集合来对item进行刻画，通过这种方式来对user、item以及user-item之间的关系进行刻画，并同时引入时间因素。具体来说，文章将一个时间片内user的embedding做attention聚合来当作item在该时间片内的embedding，并将一个时间片内item的embedding做attention聚合当作user在该时间片内的embedding，将同一时间片内信息进行聚合的方式可以在一定程度上保证同一个时间片内用户兴趣不发生大的改变。另外，为了刻画长时间范围内用户兴趣的迁移，作者通过CNN来刻画时间上的序列信息，以此来对用户兴趣的迁移性进行建模。

在实验中，作者使用了Movielens、Yelp、Pinterest三个公开数据集进行实验，使用了BPR, CAMF, TF, CHNMF, NeuMF, ConvMF这些方法作为Baseline，在实验中可以看到作者提出的方法在所有数据集和评价指标上都是最优的，次优的是ConvMF的方法，作者提出的方法和ConvMF相比，都使用了user，item和时间维度的信息，但是由于作者的模型采用外积的方法建模，外积能够考虑不同维度之间的关系从而能够更好的捕捉时间维度的信息，因此取得了更优的效果。

## A Recommender System for Heterogeneous and Time Sensitive Environment

简介：本文设计了针对数字游戏推荐的推荐系统，作者认为在游戏推荐场景中，异构性和时间敏感性是较为重要的两个特点。针对这两个特点，作者设计了一个集综合数据平台、标准化回溯数据机制、鲁棒的算法平台以及实验化平台为一体的推荐系统。其中在算法部分，作者设计了基于多臂老虎机的算法来解决冷启动和时间敏感性的问题，具体来说作者在多臂老虎机针对周期性的时序特点，添加了日期和星期几的特征，针对不具有周期性的时间特征，作者在算法中设计了Karman过滤器来进行建模。目前该系统已经在多个平台的超过10个游戏中进行工作，在推荐游戏的实验中，本文设计的系统相较于CF有30%的提升，在进入游戏推荐游戏模式的实验中，文章提出的系统也能够带来1%的更活跃用户。

## CB2CF: A Neural Multiview Content-to-Collaborative Filtering Model for Completely Cold Item Recommendations

本文主要的贡献点：  
1、提出CB2CF的模型，用于建立从CB（Content Based）到CF（Collaborative Filtering）的联系，用来解决新item缺少用户交互信息的冷启动问题。  
2、提出multiview的架构，支持将一系列连续、无结构化的数据组合成输入。

与之前相似工作的区别在于：  
1、聚焦在completely cold items，完全没有CF信息，使得联合表示无法奏效；  
2、提出了一个灵活的模型架构，支持不同的输入类型的组合；  
3、产出物是CF特征，而不是user features。

本文的关键点在于CF特征和CB特征的提取，其中CF特征：  
对user-item矩阵，使用BPR的方法，得到item vector。

而CB特征则使用了多种方式来构造：  
1、对item的描述文字，使用Word2Vec的方式，得到前L个words的embedding，小于L个word长度的，使用0向量进行padding；  
2、对item描述文字的word vocabulary构造k-means聚类，然后将描述文字使用soft alignment的方式对应到具体的中心点，得到BOW表示；  
3、构造tag的one-hot 向量；  
4、使用item的数字信息（电影上映年份等），直接作为一种输入信息

在训练CNN网络时，对比是否固定w2v vector输入，发现不固定的方式效果更好，对比多种不同大小的卷积核并行来卷积，效果没有提升，对比random dropout（固定的drop概率：0.2）与基于词频动态变化的drop概率，效果无明显变化，对比CNN和BOW网络后发现CNN效果较好。实验还表明，对大规模训练样本而言，仅使用CNN对描述文字的text信息进行抽取，已经可以达到非常好的效果，所以在实际应用中可以对模型进行一定的简化。

**SESSION: Algorithms: Large-scale, constraints and evaluation**

## Personalized Diffusions for Top-N Recommendation

通过items之间的相似性构造graph，之后使用随机游走的方式，将用户的历史行为在item graph上进行扩散，可以有效解决数据稀疏性问题。但这种方式将所有用户等同对待，忽略了用户行为的差异性，因此提出Personalized Diffusions的个性化扩散架构，通过学习user-specific 和 item-model-aware的多权重衰减机制来对排序函数进行近似，本方法属于neighborhood-based和graph-based两类的中间类别。

本文通过严谨的公式推导，证明可以将排序函数使用不同的权重衰减机制来进行模拟近似。  
* 在模型训练时，首先构造item的graph，item之间的相似度度量，可以采用COS或SLIM两种方法。  
* 其次，在进行随机游走过程中，可以结合扩散模型的方式PAR 或者采用 纯随机游走的方式Free。  
其中PAR需要构造D矩阵（由PageRank和Head Kernel两种常见扩散模型），效果明显优于Free版本，尤其是通过COS相似度构造item graph的情况下，这是由于Free版本容易受到次显性特征影响，使得user-specific的信息在随机游走过程中被丢失，存在较大的陷入局部最优的风险，而结合了扩散模型的方式则更为鲁棒。

本文采用 leave-one-out evaluation 训练方式，评测集合是用户liked-item + 999个随时选取的unseen item  
评估标准为 HR@n ARHR@n NDCG@n，在多个参数和评测结果上，基于本方法得到的效果均明显优于item-based结果。此外，当数据集合过大的时候，本算法的计算的瓶颈在于构造随机游走时的概率转移矩阵，这可以是例行线下更新的，从而使得整体算法可以做到实时。

## Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations

很多推荐系统运行中需要对大规模的candidate进行检索以及打分，通常为了解决数据的稀疏性以及power-law现象(可以直观理解为赢者通吃)，一般会引入item本身的content特征。

不同于现有的很多基于内容感知的矩阵分解方法，本文引入了双塔结构的深度神经网络，其中一个用来编码item特征，另一个来编码用户特征，并且训练的时候利用in-batch的item来计算loss function，为了解决其此方法可能带来的采样偏差，本文提出了一种算法可以用来修正样本的偏差，并且通过理论证明和实验验证了该算法的有效性。本文还介绍了基于本样本偏差修正方法建立的大规模推荐系统在Youtube的实践。

![avatar](/images/rec/rec-39.png)

主要贡献：

* 基于数据流的item频率估计，用以有效解决抽样偏差，并且证明了该方法对于item的变动以及频次分布的变化有着很好的鲁棒性。  
* 提出了一个用于大规模检索系统的generic模型框架，并且将上述提出的item frequency的计算结果包含进了batch softmax的交叉熵损失中，用以解决sampling bias的问题。  
* end to end的介绍了整个youtube推荐系统的建设，包括模型的训练，索引，serving等各个组件。  
* 离线和在线实验分析。

## When Actions Speak Louder than Clicks: A Combined Model of Purchase Probability and Long-term Customer Satisfaction

背景是微软应用商店的游戏推荐，游戏可能出现demo很炫酷但是实际购买之后发现并不好玩的情况，因此需要考虑用户的长期满意度。

作者解决这个方法并没有用普通的神经网络多任务模型，而是更加适用小数据量的采用变分贝叶斯的方法（其中一个实际的数据集才57k样本），作者假设购买为一个伯努利分布，而满意度是一个高斯分布，通过假设多个带有先验的其他参数来建模样本后验分布，但是遇到的一个实际问题是采用变分推断的时候，高斯先验和sigmoid不是共轭的，导致求解困难，作者用了一个叫做Jaakola-Jordan logistic bound的方法来放缩进而使求解变得简单（计算期望方差等平凡操作），而预测过程也是求解分布的期望方差的过程。

基于概率图模型的方法具有较漂亮的数学结果，但是对先验的假设以及对大数量的优化都是较复杂的问题，但是提供了一些具体问题的解决思路，比如活动级别或者权益级别的问题上，样本量很少，通过变分推导等方法可以提供神经网络之外的解法。

## Uplift-based Evaluation and Optimization of Recommenders

* 背景  
多数时候，推荐系统的使命是促成交，而学术界对于它的评估多数停留在准确度上，比如01分类准确度、打分准确度、top k准确度等。然而，准确度跟更多成交并不完全一致：很多东西即使不推荐，用户也会购买，这部分推荐流量就浪费了。过去文献虽然有部分工作以增量收益（uplift）作为评估，但很少从模型设计就开始考虑这个问题。这里隐含一个难题：一个物品如果被推荐且购买了，则无法知道这个物品如果不被推荐是否会被购买；同理一个物品如果没被推荐且没发生购买，同样无法知道如果被推荐它是否会被购买。这个难题在离线评估中尤其突出（无法做在线ABtest）。

* 方法

1. 提出一种针对uplift的离线评估方式

  * Inverse propensity score (IPS)是经典的衡量推荐效果的办法，它定义如下：
  
  &nbsp;![avatar](/images/rec/rec-40.png)
  
  这里 $S_T，S_C$ 分别是推荐和未推荐的item集合，$Y_n^T = 1$ 表示item n被推荐且有购买，$Y_n^C = 1$ 表示item n未被推荐但有购买，$X_n$ 是feature，$e(X_n)$ 一般可以解读为推荐概率（严格来说是用于解耦推荐与否，这里不展开）
  
  * 本文提出一种基于推荐日志计算IPS的方法:
  
  &nbsp;![avatar](/images/rec/rec-41.png)
  
  这里 $L_u^M，L_u^D$ 分别是待评估模型M和日志D针对用户u的推荐结果集合，上面式子是“模型M和日志D均推荐”的交集中购买数量（用IPS矫正）减去“模型M推荐但日志D未出现”的购买数量（用IPS矫正），前者是推荐且购买的量，后者是自然购买数量，相减则是增量。这里可能是本文最大的创新。
  
2. 修改经典pointwise和pairwise模型，使它们直接优化uplift的评估目标

![avatar](/images/rec/rec-42.png)

其中line 3是挑user，line 4是挑item来源，即正负样本均衡采样（R-P代表推荐且购买、R-NP推荐不购买、NR-P不推荐但购买、NR-NP不推荐不购买），line5-13是定义正负样本，其中R-P为正，R-NP和NR-P为负，NR-NP一定概率为正；

* 结果  
Uplift的方法在Uplift的评估指标里大幅度超过准确度导向的算法，细分数据还能看到非Uplift容易推热门商品，而Uplift算法则会兼顾一些非热门品类

![avatar](/images/rec/rec-43.png)

**SESSION: Using side-information and user attributes and cold-start in recommender algorithms**

## Deep Social Collaborative Filtering

简介：近年来，大多数的推荐系统都基于协同过滤来对用户和item之间的关系进行建模，除了用户和item之间的关系之外，用户之间构成的社交网络也对用户兴趣的刻画起着至关重要的作用，另外基于深度学习的推荐系统也表现出了较好的性能，然而这些方法都只利用了用户的直接邻居，没有很好的利用社交网络的全部信息，包括用户的高阶邻居，同时这些方法并没有对邻居的信息加以区分，选择较为有用的信息。

鉴于这些方法的缺点，文章提出了深度社交化的协同过滤算法，具体做法是首先对于user和item的一个互动，模型对该互动学习一个embedding，学习的方法是将user的embedding、item的embedding以及本次互动的分数embedding拼接后利用mlp来进行学习，通过这种方法来将互动分数信息引入。为了利用社交网络的信息，作者通过随机游走来实现，作者会对每个用户进行随机游走，游走到的用户节点作者认为对一个user、item的互动是有影响的，但是并不是邻居用户节点的所有item信息都有影响，只有邻居采纳的与起始item最想关的item信息才有效，因此形成了 ${(u_0，i_0)，(u_1，i_1)，...，(u_n，i_n)}$ 的序列，利用前述的方法对序列中的每个元素$(u_x，i_x，r_x)$学到embedding ex，然后通过Bi-LSTM来对该序列的时间性进行建模，Bi-LSTM会对正向、反向的时间关系同时进行建模，得到融入了时间因素的序列综合embedding,该表征再与user embedding和item embedding结合来对最终的rating进行预测。

在实验中，作者使用了Ciao和Epinions两个公开数据集，数据集较小，一共大概一万的用户，几十万的item，文章采用MAE和RMSE来作为推荐任务的评估指标，对比方法包括PMF，SoRec，soReg，SocialMF，TrustMF，NeuMF，DeepSoR，GCMC+SN，其中PMF和NeuMF是纯协同过滤的方法，不包括社交网络信息，DeepSor和CGMSN是引入社交网络的推荐算法，在实验中作者发现引入社交网络对推荐结果有着明显的增益，同时引入深度学习也有一定提升，作者的方法也证明了高阶邻居对推荐效果有着重要正向作用。

**POSTER SESSION: Short papers with poster presentation**

## PAL: A Position-bias Aware Learning Framework for CTR Prediction in Live Recommender Systems

应用场景是华为应用商店的应用推荐，主要是考虑样本的位置bias, 排在前面的item更可能被曝光及点击。文章对比的基线主要是将排序位置作为特征的方法(pos as feature)，该类方法对于离线预测的场景比较适用，但是在线预测的时候，因为取不到候选item位置，导致只能通过其他方法近似，比如文章提到，对每个位置搜索最佳的item后组成推荐结果，或者离线找到一个合适的位置，在线预测的时候，所有的item都取该位置来进行预测，但是这两种方法存在效率或者效果的问题。

文章对位置的注意概率($p_{seen}$)进行了单独的建模，全局共用该参数，实现了item的无偏点击概率和位置注意概率的解耦，排序的时候无需考虑位置信息，按照无偏点击概率降序排列即可，实际上该排列就是最佳排列，总的点击概率 $\sum p_{seen}*pCTR$ 最高（由柯西不等式可得）

对于我们的应用场景来说，该类问题比较常见，预期也会带来一些收益。另外想到一个问题是负样本的偏置问题，因为应用商店的一次推荐只能有一次点击，但用户可能会有多个感兴趣的item，导致负样本里面会包含部分正样本，可将一次推荐作为一个整体来建模，跟作者交流后觉得以后可以尝试下。与此有点类似一个问题是对于我们之前dsp的实时竞价场景，也有样本bias的问题，主要是体现在用户点击一条广告前可能已经浏览了多次该广告，历史的浏览对该次点击是有正向作用的， 我们通过对历史贡献的建模，使得竞价效果明显提升(20%+)。跟作者交流时，作者觉得虽然不是一个领域的问题，但是可以借鉴下。

![avatar](/images/rec/rec-44.png)

图中可见相对将固定位置作为特征的方法，效果提升较明显

## Traversing Semantically Annotated Queries for Task-oriented Query Recommendation

本文提出通过两步操作，从语义标注的query语料集合得到面向任务的推荐query的算法。  
1、构造entity-context的graph：首先对query log进行name-entity的标注，将原始的query切分为entity和context两部分，然后基于entity和context在query中的共现概率来构造graph。

2、基于graph + input 来应用多种策略进行task推荐

探索三种不同的图遍历策略：  
1）Direct Expansion (DE) 直接基于query中的entity在graph中进行检索，存在的问题是可能无法召回语料库内共现较少的context，diversity较差；  

2）Syntagmatic Expansion (SE) 对entity做语义扩展（同义词），使用entity的语义向量表示进行检索最相近的50个entity，之后结合这50个entity各自最相关的context来构造推荐query；  

3）Analogical Expansion (AE) 选取在graph中与entity的context最相近的50个entity，之后利用这些entity从session中搜索后续的entity。利用vector之间的简单加减操作，对后续的entity进行挑选，得到ei。由于直接选取与ei相关的context可能会导致话题漂移，但找e0的context则存在diversity问题，采用层次RNN的encoder-decoder生成方式得到context、最终需要对生成的context集合，结合与graph内的context计算embedding的偏移，做一致性约束。

相比传统的基于整句query进行推荐的方法，使用核心entity进行推荐可以解决长尾query覆盖率低的问题（统计包含name-entity的query占比在70%以上），但作者并没有考虑entity间隔的轮数、多轮搜索的语料数据可能比较稀疏的问题。此外本文考虑的query都是单entity的情况，单独的DE、SE、AE策略的评测结果都相比baseline较差，使用了maximal marginal relevance (MMR）的排序模型进行合并后效果有提升，但AE作为paper重点介绍的策略，单独的效果最差，也没有进一步分析DE+SE这样的组合效果，实验结果并不全面。

**Late-Breaking Results**

## Tripartite Heterogeneous Graph propagation for large-scale social recommendation

* 内容介绍：

在推荐系统中，user与item的关系表示非常重要，GNN是一种有效的关系表示方法，不过在推荐系统中使用GNN存在一些挑战，如complex noisy connections、high heterogeneity 和over-smoothing等问题。本文提出一种将GNN有效应用于推荐系统的一种方法HGP，其中对于大规模社交网络图构建的复杂性，引入group的概念将user-item的结构转化为group-user-item，在此基础上可构建Tripartite Graph，相比于传统的social graph，减少了边的个数和路径的复杂度。对于平滑问题，HGP是将节点嵌入到一个基于PageRank的个性化传播方案中，然后分布作用与group-user graph和user-item graph，并对每个图中的节点嵌入使用attention机制进行集成。在实际的社交网络推荐数据上，相比多种异构图网络表示算法在算法效果和性能上有较大的优势。

* 详细说明：

首先对比传统社交网络图和THGP，左侧是传统社交图网络，右侧是本文提出的HGP。

![avatar](/images/rec/rec-45.png)

从上图可以看出，传统的social graph结构较为复杂，存在大量的节点和边，THGP的主要区别是将用户分成多个group，避免user-user直接关联，减少了图的复杂性，通过多步的连接依然能达到同样的信息传播的效果。

下面介绍HGP模型，是文章核心说明的内容，其完整模型架构图如下：

![avatar](/images/rec/rec-46.png)

将user、item和group构成节点和边类型的复杂网络，HCP能够为每种边类型独立传播邻域，然后将最终的节点表示与注意力模型相结合。

对于一个异构图G，将节点划分为多种不同类型：$x_1，x_2，...，x_n$，分别用不同的NN预测 $H_i = f_i(x_i)$，将结果合并得到H，HGP如下方式来学习深度节点表示：

![avatar](/images/rec/rec-47.png)

其中，Ar是仅包含类型为r的边的邻接矩阵，R是边类型，$A^r$表示异构归一化邻接矩阵，Zr(k)是节点的表示，K表示第k step。a为平衡neighborhood影响的参数。

HGP通过attention model将这些节点表示合并。

![avatar](/images/rec/rec-48.png)

其中，$d_k$ 表示输入查询和key的维度，将最终节点表示句子与attention model结合，从z(k)_r中为每个边类型选择第i个节点，并将这些向量叠加形成矩阵 $Y_i$, HCP对 $Y_i$ 进行attention计算如下：

![avatar](/images/rec/rec-49.png)

其中，query，key，value是相同的，然后HGP将Y’_i的行连接，并将其传递到线性成，生成第i个节点的向量表示z_i.在实际的社交网络推进系统中，计算user和item表示之间的dot相似性来预测CTR。具体如下：

![avatar](/images/rec/rec-50.png)

以上就是HGP建模的完整过程，其基本实现可以总结为：HGP为每种边类型独立传播邻域，然后将最终的结点表示与注意力模型相结合，最终用user和item直接点击相似度来完成CTR的预测。

实验分析：

本文章的数据来自大型社交网络（未说明具体来源），包含group，user和item三种节点类型。其中user属于同一组，则group和user相连。当user和item有交互，则item与user相连。 有效减少了边的数量和路径复杂度。数据库总共有1645279个节点和4711208条边。使用bert和vgg16提取visual-linguistic属性，利用linear embedding将分类属性转为dense features。

实验模型包括metapath2vec、metapath2vec+EGES、MNE+EGES、FastGCN、HGP，验证指标为PR-AUC和ROC-AUC，F1 score。具体效果如下：

![avatar](/images/rec/rec-51.png)

其中metapath2vec不能使用节点属性，无法完成CTR预测，FastGCN存在over-smoothing问题，HGP的性能明显优于其他的异构图网络模型，切HGP能够在半天内达到收敛，能够满足实际应用日更新的推荐场景。

下面这张图给出不同传播步骤下HGP性能比较。HGP需要至少两步才能获得组内其他节点信息（user-group-user），如果传播步数为3，则可以接近具有共同偏好的user的其他偏好item。当步数为10时，性能达到最佳，并避免了over-smoothing的问题。

![avatar](/images/rec/rec-52.png)

注：Over-smoothing：是堆叠多层的GNN容易产生的问题，堆叠层数越多，节点考虑的邻居个数会更多，最终所有节点的表示会趋于一致。

APPNP通过个性化的pagerank生成传播方式来避免over-smoothing。主要思想是平衡近邻和远邻。本质上是将网络做了切割。

* 总结说明：

本文将GNN表示用户的社交关系并用于推荐系统的思路比较清晰，对图的复杂度和over-smoothing的问题都有一定的借鉴意义，不过对group上的说明解释较少，个人理解group可以通过模型或自定义，类似主题或可定义的设计类型。

**Workshop: REVEAL**

## Recap: Designing a more Efficient Estimator for Off-policy Evaluation in Bandits with Large Action Spaces

这篇短文是REVEAL workshop中的一篇来自于Netflix公司的短文

* 解决什么问题

Contextual bandits是个性化推荐、广告领域非常常见的建模工具。作为开发者，我们希望一个新的策略(policy)在线上A/B testing之前，能够用一些可靠的指标离线评估其效果（通常称这些技术为Counterfactual Policy Evaluation方法)。常见的CPE方法以及问题如slides所示：IPS/SNIPS等方法偏差小但是往往会有非常大的方差，Doubly Robust之类的降低了方差但是需要额外的reward model。

![avatar](/images/rec/rec-53.png)

对于确定性策略(deterministic policy)的情况，这些方法只能利用那些logging policy和target policy选择相同action的样本。随着action空间增大，完全匹配变得越来越少，这些估计的方差也会急剧增加。Netflix的工程师针对deterministic ranker-based policy设计了一种CPE方法Recap。

* 方法

![avatar](/images/rec/rec-54.png)

Recap可以看作是SNIPS的改进，相对于SNIPS的改变是用公式中的RR来代替 $I(a_{\tau} = a_{\pi})$。RR是target policy对于logged action的排序倒数。作者称这种方式解决了上述的只能利用action完全匹配样本的问题，个人理解就是使用RR来近似target policy选择logged action的概率。

* 效果：

1) 模拟数据实验：对于较小的action空间，Recap明显带来较大的bias，但是随着action空间增大，Recap相对于IPS\SNIPS都有更小的variance。MSE也更小  
2) Netflix真实案例：离线Recap评估和线上ab testing的真实表现高度相关，证明其有效性

![avatar](/images/rec/rec-55.png)

Recap尝试解决痛点在我们业务中也非常常见，作者声称在Netflix内部Recap已经在很多个场景用来离线评估策略效果，我们也可以在业务中尝试。但是这个短文缺乏像SNIPS/DR方法做的Bias/Variance理论分析。作者也称他们的后续工作是补充论文分析，尝试找到直接优化Recap的训练方法。

**Poster**

## Large-scale Interactive Recommendation with Tree-structured Policy Gradient

* 内容介绍：

这篇文章说明是强化学习在交互式推荐系统（IRS）中的应用。近些年，IRS技术在大多数的个性化服务中运用，与传统的推荐系统不同，IRS不再是静态的推荐内容，而更注重用户的反馈，并在交互过程中不断优化推荐内容。在很多研工作中引入强化学习来对这种连续推荐过程建模，但因推荐场景涉及的item数目往往非常大，而大多数现有的RL方法无法处理如此大规模离散动作空间问题，效率非常低。本文提出一种框架：tree-structured policy gradient recommendation（TPGR），基本思路是在所有item上构建平衡层次聚类树，item的选择转化为寻找一个从root到指定叶子节点的路径。该方法在实际数据集上进行验证，取得了state-of-the-art的效果。

* 详细介绍：

TPGR模型的主要思路是先对item集合做预处理聚类，避免从海量数据中遍历，从而解决效率问题。其模型框架图如下：

![avatar](/images/rec/rec-56.png)

左侧展示了一棵平衡树结构，对应着将item集合进行层次聚类的结果，每个根节点对应一个item。右侧是说明如何基于树进行决策，其基本思路是将每一个非叶子节点对应为一个policy network，从根节点到叶子节点的路径中包含了多个policy network并进行决策。TPGR模型能够大幅降低决策的复杂度，从O(\|A\|)降低到O(d*\|A\|^1/d)，其中d为树的深度。

* 实验说明：

数据：本文使用MovieLens和Netflix的数据进行实验，不同数据集的内容如下：

![avatar](/images/rec/rec-57.png)

实验设置；对每个数据集，将用户按8：2进行划分，80%用于训练，20%用于测试，episode length统一设置为32，reward的参数α实验了三种，分别为（0，0.1，0.3），对item不进行重复推荐。

本文选择了7个算法进行比较对比，其推荐效果具体如下：

![avatar](/images/rec/rec-58.png)

此外，本文对不同算法的训练和决策性能进行了比较，具体如下：

![avatar](/images/rec/rec-59.png)

从表3中可以说明TPGR的训练和决策耗时较低，除DDPG-KNN（k=1）外，结合表2，可以看出k=1时效果较差，综合而言，TPGR在效果和性能上是最优的。



