---
title: 超大规模商品推荐的召回模型探索-SLRM(Sparse Logistic Regression Model)
date: 2019-06-01
categories:
- 推荐算法
tags:
- swing
---

# 摘要

本文旨在「通俗易懂」地介绍我们团队对SLRM(Sparse Logistic Regression Model)在TopN推荐系统中的应用，以及如何做到在淘宝「千亿级别」数据上落地，全文包括对该算法的剖析、变换、实现、实验等一系列完整的介绍。我们对原始的SLIM模型做了一些改进，将其变换成一个Sparse LR Model，简化了整个计算过程，然后用集团的xftrl(改进的Follow-the-regularized-Leader)来对这个千亿级别的model进行求解，最终得到一份基础I2I数据，作为召回层基础数据。经过大量的在线和离线实验，我们的算法都取得了不错的成绩，在今年的双十一大促中也起到了重要的作用。

<!-- more -->

# 背景

随着互联网特别是社交网络和电子商务的高速发展，推荐系统也在这个大数据时代取得了举足轻重的一席。近年来关于推荐系统的文献和方法也是层出不穷，各种推荐算法也都得到了长足的发展和改进。这些改进算法主要可以分为两类[1]，一类是基于记忆的CF方法(neighborhood-based collaborative filtering methods)，这种方法通常比较简单，易于计算，但是在结果精度上会有所欠缺(eg:item-based cf，user-based cf)，另一类是基于模型的CF方法(model-based methods),该类算法相对要复杂一些，以高昂的计算代价来换取结果精度(eg:svd，svd++);

SLIM(Sparse LInear Method)[1]算法，早在2010年就被Xia Ning等人在ICDM’10上提出，该算法是model-based CF方法中较新的一种，由于其特殊的稀疏性和并行性，可以实现快速计算———这也是我们选中该算法的原因之一(虽然后面还是踩了很多坑)。之后，在SLIM的基础上，同一实验室的学者Evangelia Christakopoulou等人又提出了GL-SLIM[2]，在这个工作中他们同时融合global和local的SLIM，通过两层的model迭代做到对user聚类的选取和权重的分配。通过对不同group的user选用不同local model，并融合上全局的模型，整个学习过程变得更加精准———由于我们团队好多工作都是基于“人群”展开的，所以这点也就成了我们选取slim的另一个重要原因，也是后续工作的重要方向。

基于SLIM算法的高精度、稀疏性、可并行计算的特点，还有SLIM算法最后可以集成user的group信息变成GL-SLIM，我们选中SLIM算法作为切入点，对其展开了一些学习、剖析、改进以及实现工作。但是面对淘宝数以十亿计的宝贝和用户，我们需要处理的数据量动辄就是千亿甚至是亿亿级别，这对算法的性能要求是个巨大的挑战。正如前面所说的，由于模型的优化迭代等因素，model-based methods 基本都伴有高昂的计算代价，会消耗大量的计算资源和时间。作为model-based method的一员，SLIM同样也面临这同样的问题。因此，如何将SLIM算法高效的在淘宝「千亿级别」数据上落地成了我最亟待解决的问题。

通过对SLIM算法原型的剖析，我们对SLIM的公式进行变形，逐步将其变换成一个简单的Sparse Logistic Regression Model———SLRM。该SLRM算法十分简洁且易于理解，整个过程可以看作是一个超大的LR(Logistic Regression)模型的求解。最重要的是，经过对算法模型的简化，我们对数据的预处理和模型的计算可以变得更加简单和方便，还可以直接使用已经成熟的求解LR模型的方式来对SLRM进行求解。目前，经过各种尝试和实验,我们最终克服了种种困难，取得了第一阶段的成果，同时也发现了一些问题，为下一阶段的工作方向奠定了基础。

由于篇幅有限，文中主要介绍SLIM算法以及优化后得到的SLRM算法的相关工作，其他背景知识和发展历史不再赘述。本文主要分为五章:第一章，介绍相关背景以及我们选取SLIM算法的出发点；第二章，剖析SLIM及GL-SLIM算法；第三章介绍我们新提出的SLRM算法及实现过程；第四章是一些在线离线实验结果及分析；第五章是对之后工作的展望；

# SLIM and GL-SLIM

## 问题定义

在开始介绍原始的SLIM算法之前，我们先把问题简单定义一下。如下图，$U$表示整体user的集合，$T$表示整体item集合。$u_i$表示user i，$t_j$表示item j。 A是行为矩阵或者评分矩阵，表示user集合对item集合的行为或者评分，简单起见，本文中的A表示用户行为矩阵。

$a_{ij}$是A中的(i,j)元素，表示 $u_i$ 对 $t_j$ 的行为,如果$u_i$对$t_j$有过行为，则$a_{ij} \geq 0$,如果$u_i$对$t_j$没有行为，则$a_{ij} = 0$。那么,TopN推荐就可以定义为:

已知: 用户集合 $U(\|U\|=m)$ 对item集合$T(\|T\|=n)$的行为矩阵$A(\|A\|=m*n)$;

求: 对于$U$中的每一个$u$，给出其未行为过的item集合$T'$中的top N个最可能被行为的item

解:  
&emsp;Step1. &nbsp;先对每个$u$未行为过的item做预测，给出可能被行为的score；(这一步之后我们可以得到一个预测矩阵$A'$)  
&emsp;Step2. &nbsp;然后将$u$未行为过的item按照score排序，给出topN推荐。

## SLIM

因为SLIM是model-based的方法，所以这里先直接给出SLIM的model公式，后面再来分析其物理意义。

如下图,公式(1)(2)是SLIM 算法对预测的行为矩阵$A'$的拟合公式，其中(1)是(2)中每个元素的表达形式。公式(3)(4)是模型的loss function，是个带约束的最优化问题，其中(4)是(3)按列拆分之后的格式。

![avatar](/images/rec/rec-7.png)

现在我们来尝试分析一下这几个公式的物理意义:首先，将公式(2)展开成下图的格式。那么，公式(1)可以解释成:如果要预测图中的$a_{ij}$元素，即，图中左侧的“?”，只需要用行为矩阵A的第i行点乘上系数矩阵W中的第j列，即，图中右侧的
$u_i$行点乘$w_j$列。接着，我们再来细看这幅展开后的图。可以看出，矩阵A中的$u_i$行就是user i的历史行为，而$w_j$列则对应了每个item对item j的贡献度(影响力、相似度)。那么，换句话说，要预测user i对item j的行为概率，可以用user i曾经行为过的item乘上相应的权重后求和来近似表达。

![avatar](/images/rec/rec-8.png)

所以，有了上面的分析，我们知道了系数矩阵W其实就是各个item之间的贡献度，在这里我跟愿意把它理解为相似度(eg:$w_{ij}$就表示了item i和 item j之间的相似度)。故，SLIM算法巧妙地把用户历史行为的item和需要预测的item之间的相似度用矩阵的形式加以表达，形成了一个稀疏的线性模型(Sparse LInear Method)。

下一步就是如何准确的求解这个系数矩阵W。其实，如果不加任何约束条件，W的最优解一定就是单位阵了。所以，为了使求得的解不是单位阵，而且得到的结果足够集中(稀疏)，SLIM算法对其loss function加了一些限制条件，并对参数做了正则化，如公式(3)是整体loss function。将公式(1)代入公式(3),可以很快得到公式(4)。这也是SLIM的另一个重要特征———列独立，因此SLIM的求解过程可以按列分布式计算，从而提高运算速度。另外，因为我们的目标是得到一个稀疏的系数矩阵W，所以文献[1]中还提到可以用itemKNN对item做feature select，进一步加快运算。

## GL-SLIM

因为SLIM算法对所有的user都使用了同一个model，所以只能得到一个global的SLIM模型，但是对于那些小众的、有特殊偏好的user会有重大损失。如下图中的例子，如果只考虑Subset A，那么item c和 item i 相关性一定很高(因为item c和item i都被所有用户同时行为过)；如果只考虑Subset B，那么item c和 item i 相关性应该为零(因为没有用户同时行为过item c和item i)；而对于整个user集合而言，item c和item j的相关性又会有所不同。

![avatar](/images/rec/rec-9.png)

基于这一个点，文献[2]中提出了一种loacl SLIM算法，并将local和global结合，提出了GL-SLIM算法。有了前面对SLIM的理解，这里我也直接给出GL-SLIM算法的公式，如下图。

![avatar](/images/rec/rec-10.png)

图中的公式是GL-SLIM的模型公式，对应SLIM中的公式(1)。其中，$\hat{r_{ui}}$表示user u对item i的预测得分；$p_u$表示user的group划分，用1到K表示；R矩阵对应SLIM中的行为矩阵A，
$R_u$表示global行为矩阵中的第u行(对应user u的历史行为)，$R_{u}^{p_u}$表示group $p_u$的行为矩阵的第u行(若user u不属于 $p_u$ 则该行都为0)；同样的，S矩阵对应SLIM公式中的W矩阵，是需要求解的系数矩阵，
$S_i$表示global系数矩阵中的第i列，$S_{i}^{p_u}$表示group $p_u$对应的系数矩阵中的第i列；最后，$g_u$ 表示在model中global部分所占的权重。

可以看出，在GL-SLIM中，model由global和local两部分组成，而需要求解的部分有3部分，第一部分是global的系数矩阵S，第二部分是local的系数矩阵
$S^{p_u}$(有多少个group就要解多少个local的S)，还有一部分是权重系数$g_u$($g_u$ 对于每一个group都是不同的)。

怎样才能做到对这么多参数的求解呢？GL-SLIM算法采用了嵌套两层迭代的优化办法，如下图的公式和流程图。

![avatar](/images/rec/rec-11.png)

我们先来看上面的loss function，这是按列拆分之后的形式。作者把$S_i，S_{i}^{p_u}，g$三大变量都集成到了一起，其中g表示user对应的$g_u$权重向量，$g'$表示对应的$1 - g_u$的权重向量。可以发现，如果固定g的取值，那么整个公式就会变一个求解系数矩阵的带约束的最优化问题，通过迭代就可以顺利的求出
 $S_i$ 和 $S_{i}^{p_u}$；然后，在 $S_i$ 和 $S_{i}^{p_u}$ 都确定的情况下，整个公式又变成了关于$g_u$的最优化问题。
 
因此，通过分别固定【 $g$ 】和【 $S_i，S_{i}^{p_u}$ 】，嵌套两轮迭代就可以得出最优解，如下面的流程图。  
* 首先，初始化 $g_u = 0.5$(固定变量 $g$ )；  
* 然后用一个简单的聚类方法对user进行group划分；  
* 接着，根据初始化的group和$g_u$，求解出当前的 $S_i$ 和 $S_{i}^{p_u}$；再然后，对每个user依次计算将该user放入每个group时的loss，保留loss最小的情况；不断迭代上面两层，直到user的group划分不再变化；  
* 最后，得出 $S_i，S_{i}^{p_u}，g$。

![avatar](/images/rec/rec-12.png)

# SLRM

前面几章介绍了SLIM、GL-SLIM算法和我们选择这个算法的出发点，一切看着都那么完美，那么水到渠成，但是理想很丰满，现实却特别骨感。虽然SLIM算法具有列独立的特点，可以分布式计算，但是面对淘宝亿亿级别的数据量一切都是浮云。所以，怎样能把SLIM算法在我们亿亿级别的数据量上落地，成了最棘手的事情。我们尝试过作者的原版MPI框架代码，gitbub上的librec算法包，还试过自己用MR框架实现，都遇到了这样那样的问题。

## SLRM

穷则思变。在经历了处处碰壁之后，我们又仔细分析了SLIM算法原型。其实SLIM算法的核心思想就是把用户的历史行为乘上一个系数，然后求和，以一个Sparse Linear Model的形式来对用户行为做出拟合(预测)。既然是线性模型，为什么一定要以矩阵的形式，一列一列的求解呢？能不能直接用一个简单的LInear Model一次性求解呢？带着这些疑问，我们尝试着对SLIM做了一次大胆变形。

首先，对于SLIM的模型公式(1),我们做如下变换。简而言之，对于公式中的$w_j$部分,我们把W矩阵的每一列都合并成一列，形成一个大的w列；对于$a_i$部分，我们将其保留在第j位，然后其他位置用零向量填充。这样变形之后，我们就把整个W矩阵合成了一个大向量 $\theta$，而user的历史行为则用$x^T$
表示，即$y = \check{a_{ij}} = x^T * \theta = \theta^T * x$，成了一个简单的LInear Model。也就是说，我们可以把user的历史行为看做是样本，然后用这个线性模型来求解 $\theta$ ，就能得到我们想要的系数矩阵了。

$$ \widetilde{a}_{i,j} 
=a^T_i*w_j
= \begin{pmatrix}0 \\ 0 \\ \vdots \\ a_i\\ \vdots \\ 0 \\ 0 \end{pmatrix}^T*  \begin{pmatrix}w_1 \\ w_2 \\ \vdots \\ w_j\\ \vdots \\ w_{n-1} \\ w_{n} \end{pmatrix} 
=x^T*\theta
=\theta^T*x $$

进一步的，我们把用户历史行为用0\1来表示，从而把 $y = x^T * \theta$ 这个线性模型变成了一个LR(Logistic Regression) model。为了便于理解和特征的one-hot表达，又将feature name做以下变换,即：每个feature name 都是 item-item pair，代表着两个item之间的影响(相似度)。

$$ \begin{pmatrix}w_1 \\ w_2 \\ \vdots \\ w_j\\ \vdots \\ w_{n-1} \\ w_{n} \end{pmatrix} =>  \begin{pmatrix} \begin{pmatrix}w_{1,1} \\ \vdots\\w_{1,n} \end{pmatrix}\\ \vdots \\ \begin{pmatrix}w_{j,1}\\ \vdots \\ w_{j,n} \end{pmatrix} \\ \vdots \\ \begin{pmatrix} w_{n,1} \\ 
\vdots \\w_{n,n} \end{pmatrix}\end{pmatrix} =>  \begin{pmatrix} \begin{pmatrix}item_1-item_1 \\ \vdots\\item_1-item_n \end{pmatrix}\\ \vdots \\ \begin{pmatrix} item_j-item_1\\ \vdots \\ item_j-item_n \end{pmatrix} \\ \vdots \\ \begin{pmatrix} item_n-item_1 \\ 
\vdots \\item_n-item_n \end{pmatrix}\end{pmatrix} $$

下面是一个简单例子，共有三个user(A,B,C)，三个item(111,222,333)。其中，绿色的位置是填充的0，蓝色位置是真实特征。又因为通常相似矩阵都是对称阵，所以我们可以进一步将模型缩小(删除222-111、333-111、333-222)。

![avatar](/images/rec/rec-13.png)

至此，我们已经把SLIM变换成了SLRM(Sparse Logistic Regression Model)。相比较SLIM算法，SLRM只用了一个简单的LR model，模型更易于理解，而且可以利用大量的现有方法进行求解。另外，从上面的分析可以看出，每一组特征权重就代表着两个item之间的相似度，可以直接用于I2I数据的产出。

## 求解

其实，通过SLRM算法我们已经将问题简化成了一个LR问题，所以为了将SLRM算法运用在我们的淘宝数据上，我们需要做的就是很熟悉的3件事:1、sample；2、feature；3、train model；具体的实现方法可以有很多种，下面介绍我们的方案。

**样本采集**：正样本的处理比较简单，直接将user一天的点击行为作为正样本。负样本要复杂一些，首先，找出一天之内所有被一个user同时点击过的item pair，形成一个集合；然后，对于一个user u，若u只点击过item pair中的一个item，那么就以一定概率r保留未被行为过的item作为负样本。由于被同时点击的item pair有很多，所以一般概率r都很小，比如:0.000001。

**特征抽取**：按照前面的分析，特征其实就是用户历史行为过的宝贝和当前样本宝贝的组合，得到itemA-itemB。具体地，我们保留user 6天的点击行为,若6天内被点击的item和当前样本item属于近似类目(我们对相似类目做了抽取)，那么就保留这个特征。注意，因为相似矩阵的对称性，我们只保留一半的特征(eg:保留111-222，舍弃222-111)，而且，itemA ≠ itemB。

**模型训练**：我们使用的是PS团队最新开发的xftrl，该方法配有L1、L2正则，可以满足我们对模型稀疏性的要求。最关键的是，我们的学习目标是淘宝亿亿级别的i2ipair，虽然经过稀疏化和feaure select但是面对的model还是十分庞大。而xftrl可以支持千亿级别的模型训练。

# 实验

离线指标采用文献[1]中使用的

$$ HR = \frac{\#hits}{\#users} $$

$$ ARHR = \frac{1}{\#users} \sum_{i=1}^{\#hits} \frac{1}{p_i} $$

其中，#users=user总数；对于一个user，如果其测试集中item在最后的topN list中，即为hit，#hits=所有hit用户的个数；p是测试集宝贝在topN list中的序号；

# 思考

* 就现状看，model的计算性能已经成了瓶颈，后面会先尝试提升计算性能，包括特征预擦除和特征动态擦除。特征预擦除指的是训练前对不重要的负向特种提前擦除。特征动态擦除指的是在训练过程中对不重要的旧特征做定期擦除。  
* 以SLIM为子单元，进一步实现GL-SLIM。由于计算性能受限，所以目前看来这个一步困难重重，需要先考察可行性或者寻找变向解决之法。  
* 其实SLIM算法很强大，产出一份基础I2I数据只是其中一个用法，我们还可以尝试用SLIM的思想来做rank，把user行为的itemlist做为特征 或者 将group信息加入到rank过程中，这部分有待思考细节。  



# 参考文献

[1] X. Ning and G. Karypis. Slim: Sparse linear methods for top-n recommender systems. InProceedings of 11th IEEE International Conference on Data Mining, 2011

[2] E. Christakopoulou and G. Karypis. Local Item-Item Models for Top-N Recommendation. RecSys’16



