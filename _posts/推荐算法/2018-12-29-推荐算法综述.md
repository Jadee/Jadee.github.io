---
title: 推荐算法综述
date: 2018-12-29
categories:
- 推荐算法
tags:
- 推荐系统
---

# 背景

本文主要介绍推荐系统中传统机器学习算法与深度学习算法，写这篇文章的主要目的是对业界主流推荐算法的一些总结，让读者对主流推荐算法的底层实现有一定了解，从而在业务实践过程中更好地理解算法，运用算法。

<!-- more -->

文章总共分3部分，第1部分为传统机器学习算法的介绍，第2部分是深度学习基础知识介绍，第3部分是深度学习推荐算法的介绍。

其中，传统机器学习算法总共介绍了10种推荐算法，深度学习介绍了14种方法

# 传统机器学习算法

本章节将介绍10种常见的推荐算法，并且列举一些实际的例子，详细介绍如下：

### 基于CF的推荐算法

#### 算法简介

CF（协同过滤）简单来形容就是利用兴趣相投的原理进行推荐，协同过滤主要分两类，一类是基于物品的协同过滤算法，另一种是基于用户的协同过滤算法，这里主要介绍基于物品的协同过滤算法。

给定一批用户，及一批物品，记 $V_i$ 表示不同用户对物品的评分向量，那么物品 $i$ 与物品 $j$ 的相关性为：

$$ sim(i, j) = cos(\vec{V_i}, \vec{V_j}) = \frac{\vec{V_i} \cdot \vec{V_j}}{\| \vec{V_i} \| \|\vec{V_j}\|} $$

上述公式是利用余弦公式计算相关系数，相关系数的计算还有：杰卡德相关系数、皮尔逊相关系数等

计算用户 $u$ 对某一物品的偏好，记用户 $u$ 对物品 $i$ 的评分为 $score(u,i)$，用户 $u$ 对物品 $i$ 的协同过滤得分为 $rec(u,j)$。

$$ rec(u, j) = \sum_{i=1}^n score(u, j) \cdot sim(i, j) $$

#### 业务实践

以购物篮子为例，业务问题：根据用户的历史购买商品记录，给用户推荐一批商品。协同过滤算法实现方法如下。

* Step1：计算物品之间的相关系数

&emsp;&emsp;&emsp;记 $buyers_i$ 表示用户购买商品的向量，记 $buyers_i = (\ldots, b_{u,i}, \ldots), u \in U$，其中 $U$ 表示全库用户集合，$b_{u, i}$ 表示用户 $u$ 对商品 $i$ 的得分，定义如下：

$$ b_{u,i} = \left\{
\begin{array}{rcl}
0       &      & {表示没有购买}\\
\frac{1}{\alpha t}       &      & {其中t表示购买距离现在天数，\alpha 表示时间衰减系数}
\end{array} \right. 
$$

&emsp;&emsp;&emsp;那么商品 $i$ 与商品 $j$ 的相关系数如下：

$$ sim(i,j) = \frac{buyers_i \cdot buyers_j }{\| buyers_i\| \| buyers_j\|} $$

&emsp;&emsp;&emsp;上述公式是是利用余弦公式计算相关性，含义是商品的用户购买向量夹角越小越相似。此外也可以运用皮尔逊、杰卡德、自定义公式计算相关性，这里不一一列举。

* Step2：计算用户对商品的协同过滤得分

&emsp;&emsp;&emsp;给定一个用户 $u$，设该用户历史购买商品记录的向量为 $history_i = (\ldots, h_{u,i}, \ldots), i \in I$，其中 $I$ 表示所有商品的集合。

$$ h_{u, i} = \frac{1}{\alpha t}$$

&emsp;&emsp;&emsp;计算给定一个物品j的协同过滤得分为:

$$ rec(u,j) = \sum_{i=1}^n h_{u,i} \cdot sim(i,j)$$

* step3：给用户推荐商品

&emsp;&emsp;&emsp;通过Step2计算用户对全库商品的协同过滤得分，取得分top 10展示给用户

### 基于关联规则的推荐算法

#### 算法简介

基于关联规则的推荐是根据历史数据统计不同规则出现的关系，形如：X->Y，表示X事件发生后，Y事件会有一定概率发生，这个概率是通过历史数据统计而来。

对于一个规则X->Y，有两个指标对该规则进行衡量。一个是支持度，表示在所有样本数据中，同时包含X和Y样本的占比。另一个是置信度，表示在所有包含X的样本中，包含Y的样本占比。

在关联推荐算法中，最主要的是如何找到最大频繁项，业界主要的做法有两种，分别为Apriori算法和FP树。但在互联网海量的用户特征中，使用这些算法挖掘频繁集计算复杂度非常高，下面我们介绍一种在业务当中简单实用的关联规则算法。

#### 业务实践

同样是以购物篮子为例，业务场景是：根据用户历史购物记录，给用户推荐商品。下面我们介绍如何构建简单的关联规则推荐算法。

* Step1：数据准备

&emsp;&emsp;&emsp;首先收集用户展示购买记录，并且关联用户在展示时刻的特征数据。设总样本数量为n条，数据格式如下：

| 样本序号 | 用户 | 特征 | 商品 | 用户是否购买（0表示否，1表示是）|
| 1 | $u_1$ | $f_{1,1}, \, f_{1,2}, \, \ldots$| $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| n | $u_n$ | $f_{n,1}, \, f_{n,2}, \, \ldots$ | $i_n$ | $b_n$ |

&emsp;&emsp;&emsp;其中用户特征可以是用户历史购买的商品ID，也可以是用户属性特征，例如：年龄、性别、居住地等等。

* Step2：特征交叉

&emsp;&emsp;&emsp;在上表中，对于同一个样本所有特征两两交叉，生成长度为2的特征规则，合并原来的长度为1的特征规则，得到关联规则数据输入表如下：

![avatar](https://upload-images.jianshu.io/upload_images/18360757-f4f63d1c2f974461?imageMogr2/auto-orient/strip|imageView2/2/w/601/format/webp)

&emsp;&emsp;&emsp;上述表中只用长度为1（原始特征）和2（原始特征两两交叉）的规则作为后面rule的候选集，不做长度为3的规则主要的考虑点是降低规则空间复杂度。

* Step3：生成关联规则

&emsp;&emsp;&emsp;首先把上表的特征展开，使得一个特征一条记录，如下表：

| 样本序号 | 用户 | 特征 | 商品 | 用户是否购买（0表示否，1表示是）|
| 1 | $u_1$ | $f_{1,1}$ | $i_1$ | $b_n$ |
| 1 | $u_1$ | $f_{1,2}$ | $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| 1 | $u_1$ | $f_{1,1} \& f_{1,2}$ | $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| k | $u_k$ | $f_{k,1} \& f_{k,2}$ | $i_k$ | $b_k$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |

&emsp;&emsp;&emsp;计算每个规则的支持度，置信度，提升度。首先作变量声明：

&emsp;&emsp;&emsp;$f$ -> $i$：表示具备特征 $f$ 的用户购买商品 $i$ 的事件  
&emsp;&emsp;&emsp;$s_{f,i}$：&nbsp;表示规则$f$ -> $i$的支持度  
&emsp;&emsp;&emsp;$c_{f,i}$：&nbsp;表示规则$f$ -> $i$的置信度

&emsp;&emsp;&emsp;$s_{f,i}$ 计算方法为：统计表3中中同时满足特征 = $f$，商品 = $i$，用户是否购买 = 0的记录条数记为 $notbuyers_{f,i}$

$$ c_{f,i} = \frac{buyers_{f,i}}{buyers_{f,i} + notbuyers_{f,i}} $$

&emsp;&emsp;&emsp;规则选择，规则可以通过以下条件进行过滤。

&emsp;&emsp;&emsp;条件1：大于等于某个值，参考值取20-100  
&emsp;&emsp;&emsp;条件2：对所有规则的支持度做降序，取75位数为参考值，$s_{f,i}$ 大于等于这个值  
&emsp;&emsp;&emsp;条件3：对所有规则的置信度做降序，取75位数为参考值，$c_{f,i}$ 大于等于这个值

* Step4：给用户推荐商品

&emsp;&emsp;&emsp;给定一个用户 $u$ 和一个商品 $i$，通过上述方法生成用户 $u$ 的特征集合记为 $F$。我们用该用户特征集合下，所有对 $i$ 有效特征的均值衡量用户 $u$ 对该物品的购买可能性 $p(u,i)$

$$ p(u,i) = avg_{f \in F}(c_{f,i}) $$

&emsp;&emsp;&emsp;通过上述公式对全库商品求top 10得分的商品推荐给用户。在实际计算当中，并非会进行全库计算，而是采用特征索引技术进行减少大量冗余计算。

### 基于bayes的推荐算法

#### 原理介绍

Bayes(贝叶斯)定理是关于随机事件A和B的条件概率相互转化的一则定理，贝叶斯公式如下：

![avatar](https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/1ad5ad6eddc451da062e7cb7bafd5266d1163295.jpg)

上述公式中，$P(B_i|u)$ 表示的含义是在发生了事件 $u$ 的情况下，发生事件 $B_i$ 的概率，$P(B_i)$ 表示事件 $B_i$ 的发生概率，$P(u)$ 表示事件 $u$ 的发生概率。

如何利用上述定理进行个性化推荐，下面我们举个业务实践的例子。

#### 业务实践

以应用商店中应用推荐为例，业务场景：当用户进入应用商店，根据用户已安装应用列表给用户推荐应用。

* Step1：问题分解

&emsp;&emsp;&emsp;给定一个用户 $u$，给该用户推荐应用 $B$，根据贝叶斯公式用户安装概率为：

$$ P(B|u) = \frac{P(B)P(u|B)}{P(u)} $$

&emsp;&emsp;&emsp;设用户的安装列表为 $\{A_1, \, A_2, \, \ldots, \, A_n\}$，把用户 $u$ 看作是事件 $\{A_1, \, A_2, \, \ldots, \, A_n\}$，为了简化问题，假设 $A_k$ 相互独立，那么

$$ P(u|B) = P(A_1|B)P(A_2|B)\ldotsP(A_n|B) = \prod_{i=1}^n P(A_i|B)  $$

&emsp;&emsp;&emsp;上述式子可以化为


$$ P(B|u) = \frac{P(B) \prod_{i=1}^n P(A_i|B)}{P(u)} $$

&emsp;&emsp;&emsp;在推荐场景中，是对一个用户计算不同应用的得分，然后作降序进行推荐。而对于同一个用户 $P(u)$ 是不变的，所以我们可以用以下公式作为排序依据

$$ sortScore(u, B) = P(B) \prod_{i=1}^n P(A_i|B) $$

&emsp;&emsp;&emsp;全库的应用集合记为 $I$，所以在贝叶斯推荐模型中主要参数有两个集合，分别为

$$ \{P(B)|B \in I\} $$

$$ \{ P(A_i|B) | B \in I, \, A_i \in I, \, A_i \neq B \} $$

* Step2：数据准备

&emsp;&emsp;&emsp;首先收集历史的用户在应用商店中应用展示记录，并且关联用户在展示时刻的安装列表，数据格式如下：

| 样本序号 | 用户 | 已安装应用 | 展示应用 | 用户是否安装（0表示否，1表示是）|
| 1 | $u_1$ | $A_1, \, A_2, \, \ldots$| $B_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |

* Step3：模型参数计算

&emsp;&emsp;&emsp;参数集合 $ \{P(B)|B \in I\} $ 的计算：给定一个应用 $B$. 根据表1，首先选中 “展示应用=B” 的样本数，记为 $showNums_B$，然后计算 “展示应用=B” 且 “用户是否安装=1” 的样本数记为 $installNums_B$，那么

$$ P(B) = \frac{installNums_B}{ showNums_B } $$

&emsp;&emsp;&emsp;参数 $ \{ P(A_i|B) | B \in I, \, A_i \in I, \, A_i \neq B \} $，给定一个应用 $B$ 及 $A_i$，根据表，首先计算 “$A_i \in $已安装列表” 且 “展示应用=B” 的样本数，记为 $showNums_{A_i,B}$，然后计算 “$A_i \in $已安装列表” 且 “展示应用=B” 且 “用户是否安装=1” 的样本数，记为 $installNums_{A_i,B}$，那么

$$ P(A_i|B) = \frac{installNums_{A_i,B}}{showNums_{A_i,B}}$$

&emsp;&emsp;&emsp;在计算 $ P(A_i|B)$ 可能会遇到样本不足的情况，导致计算出异常值，为了避免这类情况，需要根据经验加个最少安装数限制，这里我们定义为最少安装次数为100，那么：

$$ P(A_i|B) = \left\{
\begin{array}{rcl}
P(A_i)       &      & {installNums_{A_i,B} < 100}\\
\frac{installNums_{A_i,B}}{showNums_{A_i,B}}       &      & {installNums_{A_i,B} \geq 100}
\end{array} \right. 
$$

&emsp;&emsp;&emsp;其中 $P(A_i)$ 是表示在所有用户中，安装了应用 $A_i$ 用户的占比。

* Step4：给用户推荐应用

&emsp;&emsp;&emsp;给定一个用户 $u$，及一批候选推荐应用池，我们通过上述方法计算用户 $u$ 对候选池中每个应用的得分 $sortScore(u,B)$，根据这个值做降序，取top 10的应用推荐给用户。

### 基于KNN的推荐算法

#### 算法简介

KNN（K最近邻分类算法）是一种在机器学习中比较简单的算法，它的原理如下：对于一个需要分类的物品A，定义某一种刻画物品之间距离方法，找出该物品最邻近k个有已知类别的物品，这k物品中出现最多的类别即为物品A的类别。如下图：

![avatar](https://img-blog.csdnimg.cn/20190113190408164.png)

在KNN算中，最核心的一点是怎么定义物品之间的距离，这里我们简单列举几种计算物品距离的方法：欧式距离、曼哈顿距离、切比雪夫距离、杰卡德系数、夹角余弦、皮尔逊系数。

下面介绍KNN在实际业务中的运用。

#### 业务实践

**业务场景1**：以应用商店为例，在用户下载完一个应用时，触发一个“大家还下载”的推荐，下面介绍如何运用knn算法实现这个场景的推荐：

首先定义应用的维度向量，一种简单的方法是离散化所有特征，然后进行one-hot编码，得到所有维度取值0/1的向量V，例如：可以把每个用户当做一个维度，如果第n个用户安装了应用A，那么应用A在第n个维度取值为1，否则为0，运用欧式距离可以得到应用A与应用B的距离公式：

$$ d_{A,B} = |\vec{V_A} - \vec{V_B}|

给定一个应用A，通过上述公式取距离最小的4个应用出来，在用户下载完应用A以后给该用户推荐这4个应用

**业务场景2**：网络购物中，在“猜你喜欢”场景推荐一批物品给用户

通过用户的历史购物清单，运用杰卡德公式计算用户与用户的相关系数

$$sim(u,v) = \frac{ |A_u \bigcap A_v| }{|A_u \bigcup A_v|} \, \, \, \, A_x 表示购买了物品x的用户集合$$

那么用户u与用户v的距离定义为：

$$ d_{u,v} = 1 - sim(u,v) $$

给定一个用户u，首先找出这个用户最邻近的k个用户，然后在这k个用户中按照购买的用户数对物品进行降序，去除用户u已经购买的物品，取top 10个物品推荐给用户。

### 决策树算法

#### 算法简介

决策树一种经典的机器学习分类算法，主要的代表算法有ID3、C4.5、CARD，原理可以简单理解为通过对数据总结、归纳得到一系列分类规则，举个简单的例子：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811094824649-1052242257.png)

在决策树中，一个叶子节点表示一条决策规则（通常叶子节点的类目等于该节点样本最多的类目），决策树算法的目标是得到准确率高的规则，而决策规则的准确率可以用叶子节点的复杂度来衡量。

#### 复杂度计算

下面列举2种常用复杂度的计算方法, 假设有样本集X，总共的类目有n个，pi表示第i个类目的占比。

（1）信息熵：

$$ H(X) = - \sum_{i=1}^n p_i log(p_i)$$

上式中，信息熵的值越高，复杂度越高，样本的不确定性越大。

（2）基尼指数：

$$ Gini(X) = 1 - \sum_{i=1}^n p_i^2 $$

上式中，基尼指数越大，复杂度越高，样本的不确定性也就越大。

#### 裂分指标

在决策树的生成过程中，每一个节点的裂分都需要考虑选择哪个属性裂分使得系统的复杂度降低越多。不同算法选用的裂分方法有所不同。

（1）ID3：信息增益

$$G(A) = H(X) - \frac{\sum_{i=1}^n |X_i|H(X_i)}{|X|}

 其中 $H(X)$ 表示裂分前系统的复杂度，$\frac{\sum_{i=1}^n \|X_i\|H(X_i)}{\|X\|}$ 表示裂分后系统的复杂度。该值越大表示裂分方式使得系统更为有序。
 
（2）C4.5：信息增益率












