---
title: 推荐算法综述
date: 2018-12-29
categories:
- 推荐算法
tags:
- 推荐系统
---

# 背景

本文主要介绍推荐系统中传统机器学习算法与深度学习算法，写这篇文章的主要目的是对业界主流推荐算法的一些总结，让读者对主流推荐算法的底层实现有一定了解，从而在业务实践过程中更好地理解算法，运用算法。

<!-- more -->

文章总共分3部分，第1部分为传统机器学习算法的介绍，第2部分是深度学习基础知识介绍，第3部分是深度学习推荐算法的介绍。

其中，传统机器学习算法总共介绍了10种推荐算法，深度学习介绍了14种方法

# 传统机器学习算法

本章节将介绍10种常见的推荐算法，并且列举一些实际的例子，详细介绍如下：

## 基于CF的推荐算法

### 算法简介

CF（协同过滤）简单来形容就是利用兴趣相投的原理进行推荐，协同过滤主要分两类，一类是基于物品的协同过滤算法，另一种是基于用户的协同过滤算法，这里主要介绍基于物品的协同过滤算法。

给定一批用户，及一批物品，记 $V_i$ 表示不同用户对物品的评分向量，那么物品 $i$ 与物品 $j$ 的相关性为：

$$ sim(i, j) = cos(\vec{V_i}, \vec{V_j}) = \frac{\vec{V_i} \cdot \vec{V_j}}{\| \vec{V_i} \| \|\vec{V_j}\|} $$

上述公式是利用余弦公式计算相关系数，相关系数的计算还有：杰卡德相关系数、皮尔逊相关系数等

计算用户 $u$ 对某一物品的偏好，记用户 $u$ 对物品 $i$ 的评分为 $score(u,i)$，用户 $u$ 对物品 $i$ 的协同过滤得分为 $rec(u,j)$。

$$ rec(u, j) = \sum_{i=1}^n score(u, j) \cdot sim(i, j) $$

### 业务实践

以购物篮子为例，业务问题：根据用户的历史购买商品记录，给用户推荐一批商品。协同过滤算法实现方法如下。

* Step1：计算物品之间的相关系数

&emsp;&emsp;&emsp;记 $buyers_i$ 表示用户购买商品的向量，记 $buyers_i = (\ldots, b_{u,i}, \ldots), u \in U$，其中 $U$ 表示全库用户集合，$b_{u, i}$ 表示用户 $u$ 对商品 $i$ 的得分，定义如下：

$$ b_{u,i} = \left\{
\begin{array}{rcl}
0       &      & {表示没有购买}\\
\frac{1}{\alpha t}       &      & {其中t表示购买距离现在天数，\alpha 表示时间衰减系数}
\end{array} \right. 
$$

&emsp;&emsp;&emsp;那么商品 $i$ 与商品 $j$ 的相关系数如下：

$$ sim(i,j) = \frac{buyers_i \cdot buyers_j }{\| buyers_i\| \| buyers_j\|} $$

&emsp;&emsp;&emsp;上述公式是是利用余弦公式计算相关性，含义是商品的用户购买向量夹角越小越相似。此外也可以运用皮尔逊、杰卡德、自定义公式计算相关性，这里不一一列举。

* Step2：计算用户对商品的协同过滤得分

&emsp;&emsp;&emsp;给定一个用户 $u$，设该用户历史购买商品记录的向量为 $history_i = (\ldots, h_{u,i}, \ldots), i \in I$，其中 $I$ 表示所有商品的集合。

$$ h_{u, i} = \frac{1}{\alpha t}$$

&emsp;&emsp;&emsp;计算给定一个物品j的协同过滤得分为:

$$ rec(u,j) = \sum_{i=1}^n h_{u,i} \cdot sim(i,j)$$

* step3：给用户推荐商品

&emsp;&emsp;&emsp;通过Step2计算用户对全库商品的协同过滤得分，取得分top 10展示给用户

## 基于关联规则的推荐算法

### 算法简介

基于关联规则的推荐是根据历史数据统计不同规则出现的关系，形如：X->Y，表示X事件发生后，Y事件会有一定概率发生，这个概率是通过历史数据统计而来。

对于一个规则X->Y，有两个指标对该规则进行衡量。一个是支持度，表示在所有样本数据中，同时包含X和Y样本的占比。另一个是置信度，表示在所有包含X的样本中，包含Y的样本占比。

在关联推荐算法中，最主要的是如何找到最大频繁项，业界主要的做法有两种，分别为Apriori算法和FP树。但在互联网海量的用户特征中，使用这些算法挖掘频繁集计算复杂度非常高，下面我们介绍一种在业务当中简单实用的关联规则算法。

### 业务实践

同样是以购物篮子为例，业务场景是：根据用户历史购物记录，给用户推荐商品。下面我们介绍如何构建简单的关联规则推荐算法。

* Step1：数据准备

&emsp;&emsp;&emsp;首先收集用户展示购买记录，并且关联用户在展示时刻的特征数据。设总样本数量为n条，数据格式如下：

| 样本序号 | 用户 | 特征 | 商品 | 用户是否购买（0表示否，1表示是）|
| 1 | $u_1$ | $f_{1,1}, \, f_{1,2}, \, \ldots$| $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| n | $u_n$ | $f_{n,1}, \, f_{n,2}, \, \ldots$ | $i_n$ | $b_n$ |

&emsp;&emsp;&emsp;其中用户特征可以是用户历史购买的商品ID，也可以是用户属性特征，例如：年龄、性别、居住地等等。

* Step2：特征交叉

&emsp;&emsp;&emsp;在上表中，对于同一个样本所有特征两两交叉，生成长度为2的特征规则，合并原来的长度为1的特征规则，得到关联规则数据输入表如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811094304868-1816427521.png)

&emsp;&emsp;&emsp;上述表中只用长度为1（原始特征）和2（原始特征两两交叉）的规则作为后面rule的候选集，不做长度为3的规则主要的考虑点是降低规则空间复杂度。

* Step3：生成关联规则

&emsp;&emsp;&emsp;首先把上表的特征展开，使得一个特征一条记录，如下表：

| 样本序号 | 用户 | 特征 | 商品 | 用户是否购买（0表示否，1表示是）|
| 1 | $u_1$ | $f_{1,1}$ | $i_1$ | $b_n$ |
| 1 | $u_1$ | $f_{1,2}$ | $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| 1 | $u_1$ | $f_{1,1} \& f_{1,2}$ | $i_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |
| k | $u_k$ | $f_{k,1} \& f_{k,2}$ | $i_k$ | $b_k$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |

&emsp;&emsp;&emsp;计算每个规则的支持度，置信度，提升度。首先作变量声明：

&emsp;&emsp;&emsp;$f$ -> $i$：表示具备特征 $f$ 的用户购买商品 $i$ 的事件  
&emsp;&emsp;&emsp;$s_{f,i}$：&nbsp;表示规则$f$ -> $i$的支持度  
&emsp;&emsp;&emsp;$c_{f,i}$：&nbsp;表示规则$f$ -> $i$的置信度

&emsp;&emsp;&emsp;$s_{f,i}$ 计算方法为：统计表3中中同时满足特征 = $f$，商品 = $i$，用户是否购买 = 0的记录条数记为 $notbuyers_{f,i}$

$$ c_{f,i} = \frac{buyers_{f,i}}{buyers_{f,i} + notbuyers_{f,i}} $$

&emsp;&emsp;&emsp;规则选择，规则可以通过以下条件进行过滤。

&emsp;&emsp;&emsp;条件1：大于等于某个值，参考值取20-100  
&emsp;&emsp;&emsp;条件2：对所有规则的支持度做降序，取75位数为参考值，$s_{f,i}$ 大于等于这个值  
&emsp;&emsp;&emsp;条件3：对所有规则的置信度做降序，取75位数为参考值，$c_{f,i}$ 大于等于这个值

* Step4：给用户推荐商品

&emsp;&emsp;&emsp;给定一个用户 $u$ 和一个商品 $i$，通过上述方法生成用户 $u$ 的特征集合记为 $F$。我们用该用户特征集合下，所有对 $i$ 有效特征的均值衡量用户 $u$ 对该物品的购买可能性 $p(u,i)$

$$ p(u,i) = avg_{f \in F}(c_{f,i}) $$

&emsp;&emsp;&emsp;通过上述公式对全库商品求top 10得分的商品推荐给用户。在实际计算当中，并非会进行全库计算，而是采用特征索引技术进行减少大量冗余计算。

## 基于bayes的推荐算法

### 原理介绍

Bayes(贝叶斯)定理是关于随机事件A和B的条件概率相互转化的一则定理，贝叶斯公式如下：

![avatar](https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/pic/item/1ad5ad6eddc451da062e7cb7bafd5266d1163295.jpg)

上述公式中，$P(B_i\|u)$ 表示的含义是在发生了事件 $u$ 的情况下，发生事件 $B_i$ 的概率，$P(B_i)$ 表示事件 $B_i$ 的发生概率，$P(u)$ 表示事件 $u$ 的发生概率。

如何利用上述定理进行个性化推荐，下面我们举个业务实践的例子。

### 业务实践

以应用商店中应用推荐为例，业务场景：当用户进入应用商店，根据用户已安装应用列表给用户推荐应用。

* Step1：问题分解

&emsp;&emsp;&emsp;给定一个用户 $u$，给该用户推荐应用 $B$，根据贝叶斯公式用户安装概率为：

$$ P(B|u) = \frac{P(B)P(u|B)}{P(u)} $$

&emsp;&emsp;&emsp;设用户的安装列表为 $\{A_1, \, A_2, \, \ldots, \, A_n\}$，把用户 $u$ 看作是事件 $\{A_1, \, A_2, \, \ldots, \, A_n\}$，为了简化问题，假设 $A_k$ 相互独立，那么

$$ P(u|B) = P(A_1|B)P(A_2|B) \ldots P(A_n|B) = \prod_{i=1}^n P(A_i|B)  $$

&emsp;&emsp;&emsp;上述式子可以化为


$$ P(B|u) = \frac{P(B) \prod_{i=1}^n P(A_i|B)}{P(u)} $$

&emsp;&emsp;&emsp;在推荐场景中，是对一个用户计算不同应用的得分，然后作降序进行推荐。而对于同一个用户 $P(u)$ 是不变的，所以我们可以用以下公式作为排序依据

$$ sortScore(u, B) = P(B) \prod_{i=1}^n P(A_i|B) $$

&emsp;&emsp;&emsp;全库的应用集合记为 $I$，所以在贝叶斯推荐模型中主要参数有两个集合，分别为

$$ \{P(B)|B \in I\} $$

$$ \{ P(A_i|B) | B \in I, \, A_i \in I, \, A_i \neq B \} $$

* Step2：数据准备

&emsp;&emsp;&emsp;首先收集历史的用户在应用商店中应用展示记录，并且关联用户在展示时刻的安装列表，数据格式如下：

| 样本序号 | 用户 | 已安装应用 | 展示应用 | 用户是否安装（0表示否，1表示是）|
| 1 | $u_1$ | $A_1, \, A_2, \, \ldots$| $B_1$ | $b_n$ |
| $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ | $\ldots$ |

* Step3：模型参数计算

&emsp;&emsp;&emsp;参数集合 $ \{P(B)\|B \in I\} $ 的计算：给定一个应用 $B$. 根据表1，首先选中 “展示应用=B” 的样本数，记为 $showNums_B$，然后计算 “展示应用=B” 且 “用户是否安装=1” 的样本数记为 $installNums_B$，那么

$$ P(B) = \frac{installNums_B}{ showNums_B } $$

&emsp;&emsp;&emsp;参数 $ \{ P(A_i\|B) \| B \in I, \, A_i \in I, \, A_i \neq B \} $，给定一个应用 $B$ 及 $A_i$，根据表，首先计算 “$A_i \in $已安装列表” 且 “展示应用=B” 的样本数，记为 $showNums_{A_i,B}$，然后计算 “$A_i \in $已安装列表” 且 “展示应用=B” 且 “用户是否安装=1” 的样本数，记为 $installNums_{A_i,B}$，那么

$$ P(A_i|B) = \frac{installNums_{A_i,B}}{showNums_{A_i,B}}$$

&emsp;&emsp;&emsp;在计算 $ P(A_i\|B)$ 可能会遇到样本不足的情况，导致计算出异常值，为了避免这类情况，需要根据经验加个最少安装数限制，这里我们定义为最少安装次数为100，那么：

$$ P(A_i|B) = \left\{
\begin{array}{rcl}
P(A_i)       &      & {installNums_{A_i,B} < 100}\\
\frac{installNums_{A_i,B}}{showNums_{A_i,B}}       &      & {installNums_{A_i,B} \geq 100}
\end{array} \right. 
$$

&emsp;&emsp;&emsp;其中 $P(A_i)$ 是表示在所有用户中，安装了应用 $A_i$ 用户的占比。

* Step4：给用户推荐应用

&emsp;&emsp;&emsp;给定一个用户 $u$，及一批候选推荐应用池，我们通过上述方法计算用户 $u$ 对候选池中每个应用的得分 $sortScore(u,B)$，根据这个值做降序，取top 10的应用推荐给用户。

## 基于KNN的推荐算法

### 算法简介

KNN（K最近邻分类算法）是一种在机器学习中比较简单的算法，它的原理如下：对于一个需要分类的物品A，定义某一种刻画物品之间距离方法，找出该物品最邻近k个有已知类别的物品，这k物品中出现最多的类别即为物品A的类别。如下图：

![avatar](https://img-blog.csdnimg.cn/20190113190408164.png)

在KNN算中，最核心的一点是怎么定义物品之间的距离，这里我们简单列举几种计算物品距离的方法：欧式距离、曼哈顿距离、切比雪夫距离、杰卡德系数、夹角余弦、皮尔逊系数。

下面介绍KNN在实际业务中的运用。

### 业务实践

**业务场景1**：以应用商店为例，在用户下载完一个应用时，触发一个“大家还下载”的推荐，下面介绍如何运用knn算法实现这个场景的推荐：

首先定义应用的维度向量，一种简单的方法是离散化所有特征，然后进行one-hot编码，得到所有维度取值0/1的向量V，例如：可以把每个用户当做一个维度，如果第n个用户安装了应用A，那么应用A在第n个维度取值为1，否则为0，运用欧式距离可以得到应用A与应用B的距离公式：

$$ d_{A,B} = |\vec{V_A} - \vec{V_B}| $$

给定一个应用A，通过上述公式取距离最小的4个应用出来，在用户下载完应用A以后给该用户推荐这4个应用

**业务场景2**：网络购物中，在“猜你喜欢”场景推荐一批物品给用户

通过用户的历史购物清单，运用杰卡德公式计算用户与用户的相关系数

$$sim(u,v) = \frac{ |A_u \bigcap A_v| }{|A_u \bigcup A_v|} \, \, \, \, A_x 表示购买了物品x的用户集合$$

那么用户u与用户v的距离定义为：

$$ d_{u,v} = 1 - sim(u,v) $$

给定一个用户u，首先找出这个用户最邻近的k个用户，然后在这k个用户中按照购买的用户数对物品进行降序，去除用户u已经购买的物品，取top 10个物品推荐给用户。

## 决策树算法

### 算法简介

决策树一种经典的机器学习分类算法，主要的代表算法有ID3、C4.5、CARD，原理可以简单理解为通过对数据总结、归纳得到一系列分类规则，举个简单的例子：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811094824649-1052242257.png)

在决策树中，一个叶子节点表示一条决策规则（通常叶子节点的类目等于该节点样本最多的类目），决策树算法的目标是得到准确率高的规则，而决策规则的准确率可以用叶子节点的复杂度来衡量。

### 复杂度计算

下面列举2种常用复杂度的计算方法, 假设有样本集X，总共的类目有n个，pi表示第i个类目的占比。

（1）信息熵：

$$ H(X) = - \sum_{i=1}^n p_i log(p_i)$$

上式中，信息熵的值越高，复杂度越高，样本的不确定性越大。

（2）基尼指数：

$$ Gini(X) = 1 - \sum_{i=1}^n p_i^2 $$

上式中，基尼指数越大，复杂度越高，样本的不确定性也就越大。

### 裂分指标

在决策树的生成过程中，每一个节点的裂分都需要考虑选择哪个属性裂分使得系统的复杂度降低越多。不同算法选用的裂分方法有所不同。

（1）ID3：信息增益

$$G(A) = H(X) - \frac{\sum_{i=1}^n |X_i|H(X_i)}{|X|} $$

 其中 $H(X)$ 表示裂分前系统的复杂度，$\frac{\sum_{i=1}^n \|X_i\|H(X_i)}{\|X\|}$ 表示裂分后系统的复杂度。该值越大表示裂分方式使得系统更为有序。
 
（2）C4.5：信息增益率

$$ GR(A) = \frac{G(A)}{SplitInfo_A(X)} $$

$$ SplitInfo_A(X) = - \sum_{i=1}^m p_{A,i} log(p_{A,i}) \, \, \, \, p_{A,i} 表示A属性第i个取值占比 $$

其中 $SplitInfo_A(X)$ 表示的意思是属性A的复杂度，该公式除了考虑系统纯度的增量的同时，也考虑了属性A的复杂度。该值越大表示裂分方式使得系统更为有序。（在ID3算法中，由于选择的是信息增益计算系统纯度增量，往往会选择复杂度高的属性进行裂分，复杂度高的属性取值分段会有很多，导致裂分后某些节点只有少量样本而不具备用于预测的统计意义，C4.5基于这个问题加以改进）

（3）CARD：基尼系数

$$ Gini(X|A) = \frac{|X_1|Gini(X_1)}{|X|} + \frac{|X_2|Gini(X_2)}{|X|} $$

CARD算法生成的决策树是一个二叉树，每次裂分只裂分两个节点，$Gini(X\|A)$ 表示裂分后的复杂度，该值越高样本无序性越大，$X_1,X_2$ 是 $X$ 的裂分后的两个样本集（裂分方法为遍历所有裂分可能，找出 $Gini(X\|A)$ 最小的那个点）。该值越小表示裂分方式使得系统更为有序。

### 决策树生成

输入：$D = \{(x_1,c_1), (x_2,c_2), \ldots, (x_n,c_n)\}$

裂分指标：选择一种裂分指标（信息增益、信息增益率、Gini系数）

节点裂分终止条件：选择节点最小样本数及最大深度

* Step1：选择一个可裂分的节点 $D_i$，循环计算所有属性的裂分指标，选取最优的指标使得系统最为有序那个属性作为裂分点，得到数据集 $D_{i+1},D_{i+2},…$

* Step2：所有叶子节点是否都达到了裂分的终止条件，是则执行Step3，否则执行step1

* Step3：减枝

* Step4：返回决策树T

### 业务实践

业务场景：以应用商店中应用个性化推荐为例

* Step1：构造用户画像，收集用户历史下载应用记录、已安装应用记录、用户社会属性（年龄、性别、学历、所在城市）

* Step2：构造应用画像，应用画像包括应用ID，应用类型、应用标签、应用安装量排名、应用CTR等

* Step3：样本收集，收集用户历史曝光下载应用记录（字段：用户ID、应用ID、是否下载），并通关用户ID、应用ID与用户画像、应用画像关联起来得到样本数据，得到样本数据（用户ID，应用ID，用户画像，应用画像，是否下载）

* Step4：构造模型训练样本，定义用户画像与应用画像不同类型特征的交叉规则生成模型特征，运用定义好的交叉规则对所有样本生成模型特征，得到模型训练样本（模型特征，是否下载）

* Step5：模型训练，模型训练样本训练CARD算法，得到预测模型

* Step6：模型使用，给定一个用户和应用，根据上述方法生成用户的用户画像及应用的应用画像，然后运用定义好的交叉特征规则生成模型特征，把模型特征代入模型得到预测值

## 随机森林算法

### 算法简介

随机森林（RF）是决策树与bagging结合一种分类回归算法，它由多颗决策树构成的一个bagging决策系统。当运用RF进行预测时，首先把需要把样本数据输入到每一棵决策树，每个树得到一个叶子节点，预测的时候，如果是回归问题则统计所有树叶子节点的均值，如果是分类问题则求所有树叶子节点类目出现最多的那个类。

RF每棵决策树的构建方式如下：

* Step1：用M表示数据总特征维度，N表示样本数量，m表示特征抽样维度

* Step2：有放回随机抽取N个样本作为这个树的训练样本

* Step3：对训练样本构建决策树，每次裂分前随机抽取m个特征出来，裂分特征在这m个特征中选择一个最优的裂分特征

* Step4：不作减枝直到不能裂分为止

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095037506-1708534947.png)

### 业务实践
 
在实际的业务运用中与决策树类似，在前面介绍的决策树业务实践中可以直接用RF算法替代决策树，构造的方法如上所述，重复地随机抽样样本及抽样特征构造多颗决策树，决策树的棵数需要结合分类精度及模型复杂程度判断。

## 基于矩阵分解的推荐算法

### 算法介绍

在推荐算法中，主要解决的问题是找到用户对物品的偏好得分。矩阵分解算法它的基本思想是认为用户对物品的偏好是外在表现，内在是用户对主题的偏好，而主题对不同物品又有不同的权重，通过用户->主题->物品这条链路才形成用户对物品的偏好。

矩阵分解的公式如下：

$$ U=PQ $$

其中 U 表示用户对不同物品的偏好矩阵，P 表示用户对不同主题的偏好矩阵，Q 表示不同主题对应用的权重

### 模型求解

在实际的业务实践中，往往是已知用户对物品的部分偏好得分，求解用户对未知物品的偏好得分。以应用商店广告场景为例：已知用户在端内的物品曝光点击记录，求解用户对不同广告偏好得分。

* Step1：根据样本数据构造矩阵 U

&emsp;&emsp;&emsp;根据样本数据，用户对曝光物品有点击记为1，没有点击记为0，没有曝光过的物品不赋值（记为-），示例如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095047670-1318190373.png)

* Step2：求解矩阵P和矩阵Q

&emsp;&emsp;&emsp;设矩阵U的大小为 N×M，主题数定义为 K，那么矩阵的大小是 N×K，Q矩阵的大小是 K×M，构造损失函数，如下：

$$ log(P,Q) = \sum_{i=1}^N \: \, \sum_{j=1, u_{i,j} \in \{0,1\}}^M (u_{i,j} - p_i q_j)^2 $$

其中 $u_{i,j}$ 表示矩阵 $U$ 的第 i 行第 j列元素，$p_i$ 表示矩阵 P 的第 i 行，$q_j$ 表示矩阵 Q 的第 j 列，通过梯度下降法可以求解矩阵P和矩阵Q

* Step3：预测用户对没有曝光过物品的偏好得分

&emsp;&emsp;&emsp;给定一个用户 i，需要预测该用户对物品 j 的偏好得分，公式如下：

$$ \hat{u_{i,j}} = p_j q_j $$

Step4：如何给用户推荐物品

&emsp;&emsp;&emsp;给定一个用户，通过Step3的公式计算该用户对所有物品的偏好得分，取该用户没有曝光过得分排名前10的物品进行推荐。

## 基于BP的推荐算法

### 算法介绍

BP算法是神经网络的一种算法，BP算法网络是有多层网络构成，信号的传播是由第一层网络开始正向传播到下一层网络。以3层神经网络为例，网络结构示例如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095115956-1355751636.png)

以3层神经网络关系如下：

$L_1 = f(X * w_1 + b_1) $  
$L_2 = f(L_1 * w_2 + b_2) $  
$L_3 = f(L_2 * w_3 + b_3) $

向量 X 是模型输入变量向量，$w_i$ 是 $L_{i-1}$ 层与 $L_i$ 的连接权重矩阵，$b_i$ 是 $L_i$ 的偏置向量。函数 $f$ 是一个激活函数，目前业界常用的激活函数有relu、sigmod、tanh，传统BP神经网络函数一般采用sigmod函数，如果采用该函数，那么：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095133481-678244111.png)

### 模型求解

以个性化推荐场景中点击率预估为例，上述模型参数有 $w_1, w_2, w_3, b_1, b_2, b_3$，我们通过梯度下降法求解这些参数，首先收集样本，取历史用户推荐的数据及用户对推荐反馈的数据作为样本。变量定义如下：

* nums 表示收集样本的数量。

* $(X_i,y_i)$ 表示用户第 i 个样本的数据，$X_i$ 表示样本的特征，$y_i$ 表示点击情况(0表示没有点击，1表示点击)。

* $Y_i$ 表示上述模型构造中的输出值，是关于 $w_1, w_2, w_3, b_1, b_2, b_3$ 的变量。

损失函数：常用的的定义有两种，一种是交叉熵，另一种均方差，以均方差为例：

$$los(w_1, w_2, w_3, b_1, b_2, b_3) = \frac{1}{n} \sum_{i=1}^n (y_i - Y_i)^2 $$

通过上述损失函数，运用梯度下降法求解模型参数 $w_1, w_2, w_3, b_1, b_2, b_3$。

关于**交叉熵和均方差**的差异见[**文章**](https://blog.csdn.net/liuweiyuxiang/article/details/90707375)

## 基于W2V的推荐算法

### 算法简介

W2V是在2013年由Google开源了一款用于词向量计算的工具，该算法提出的场景主要是解决NLP中词向量化的问题，传统对词向量的方法是one-hot编码，one-hot编码存在主要有两点，第一点维度极高无法直接作为模型的输入变量，第二点是词与词之间没有相关性。W2V的诞生解决了这两个问题，W2V是通过神经网络对词进行低纬度的向量化。

W2V有两种模型，一个是CBOW模型，另一个是Skip-gram模型。两个模型都是对词进行向量化，区别在于：CBOW是以一个词为输出目标，以该词邻近的词为输入；Skip-gram是以一个词为输入，以该词邻近的词为输出目标。示例如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095236887-880839011.png)

以CBOW模型为例，该模型的结构图如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095245449-1066875477.png)

各层关系为：

* Input层：以一个词为输出目标，以该词邻近的词向量为输入。

* Projection层：把Input层的所有向量叠加求和。

* Output层：首先对语料库中的所有词建立哈夫曼树编码（不使用one-hot编码，one-hot编码太稀疏）。然后为每在每个哈夫曼树节点建立一个逻辑斯蒂分类模型，模型的输入都是Projection的输出。

### 模型训练

模型的参数，模型的参数包括所有词的词向量 和哈夫曼树中每个节点的逻辑斯蒂回归参数。

哈夫曼树中的每个节点都是一个逻辑斯蒂回归函数，以输出的词作为叶子节点路径中的每个节点的分类（路径走左分支为1，右分支非0）作为训练目标。例如：上图中输出词假设为“足球”，那么路径如下：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095257140-1609754.png)
 
损失函数的构造，通过交叉熵的构造，以一个样本例，样本的输入词向量求和为XW，输入词为M，该词对应的哈夫曼树路径为T(M)，那么该样本的损失函数如下： 

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095305711-713320533.png)

把所有样本的按照上述公式计算损失函数，求和后得到模型的损失函数：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095321441-399896682.png)
 
通过梯度下降法可以求解所有词的词向量 $v_i$。

### 业务实践

场景：网络购物场景中，运用W2V+BP进行个性化推荐。

* Step1：对物品进行向量化

&emsp;&emsp;&emsp;把每个用户看作一篇文章，用户购买物品按照时间序列排序，物品看作词，带入W2V模型得到物品的向量。

* Step2：样本收集

&emsp;&emsp;&emsp;收集客户端中，对用户的物品曝光及购买记录，以用户历史购买的物品列表作为用户画像，以给用户曝光物品后用户是否购买为目标变量。

* Step3：构造 W2V + BP 的模型

&emsp;&emsp;&emsp;模型的输入有两个，第一个为用户历史购买物品的向量均值，第二个为曝光物品的向量。模型的输出为用户是否购买曝光的物品，中间用BP网络进行连接。

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095340354-1180134415.png)

* Step4：模型训练与使用

&emsp;&emsp;&emsp;模型训练：目前业界一般使用TF进行实现，BP网络的节点数及层数需要根据训练情况确定。

&emsp;&emsp;&emsp;模型使用：给定一个用户 $u$ 及一个物品 $i$，把用户 $u$ 购买物品向量均值及物品 $i$ 的向量作为模型输入，计算物品 $i$ 的模型得分。重复该操作，计算出用户 $u$ 所有候选物品的模型得分，根据物品的模型得分降序推荐给用户。

## 基于LR的推荐算法

### 原理介绍

LR（逻辑斯蒂回归）算法的本质是一个线性回归函数，该算法主要用作二分类的场景，例如点击率预估，算法公式如下：

$$ Y = sigmod(wx + b) = \frac{1}{1 + e^{-wx - b}}$$

其中 $x$ 是模型的输入

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095359647-687132556.png)

* $x_i$ 表示每个维度的输入。
* $w$ 是表示模型输入 $x$ 的系数向量，$w = (w_1, \, w_2,\, \ldots)$，$w_i$ 表示维度 $x_i$ 的权重。

### 模型求解

我们通过梯度下降法求解我们的模型。以点击率预估为例，首先收集样本。变量定义如下：

* nums 表示收集样本的数量 。

* $(X_i, \, y_i)$ 表示用户第 i 个样本的数据，$X_i$ 表示样本的特征，$y_i$ 表示点击情况(0表示没有点击，1表示点击)。

* $Y_i$ 表示模型的预测值，是关于 $w, \, b$ 的变量。

定义交叉熵损失函数：

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095411355-1974897393.png)

通过梯度下降法求解los(w,b)最小时对应的w,b即为所求模型参数。

### 业务实践

LR算法在目前推荐系统业界中，流行的做法是大规模离散化特征（one-hot编码），然后带入LR模型，以广告点击率模型为例，步骤如下：

* Step1：构造用户画像

&emsp;&emsp;&emsp;按照特征类别构造用户画像，对类别下面的所有特征进行离散化处理，例如：用户历史浏览物品记录，用户社会属性，通过模型给用户打的标签等等。

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095424210-1585252042.png)
 
 * Step2：构造物品画像

&emsp;&emsp;&emsp;构造物品画像，同样也是需要划分物品特征类别，类别下面特征离散化处理，例如：物品ID，物品标签，物品热度等等。
 
![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095431962-587798862.png)

* Step3：构造场景画像

&emsp;&emsp;&emsp;在实际的业务实践中，往往是一个模型需要用到多个场景，不同场景物品的平均点击率差别很大，为了更好地解决不同场景平均点击率不同的问题，往往需要加上场景特征。场景画像一般只有场景ID，在某些特殊场景（例如：搜索列表）可以加上位置信息。

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095439203-485677389.png)
 
* Step4：收集样本数据

&emsp;&emsp;&emsp;收集历史曝光点击数据，收集的数据维度包括:用户ID，物品ID，场景ID，是否点击。然后关联用户画像和物品画像得到模型的训练样本数据。

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095448380-2014559187.png)

* Step5：构造模型特征

&emsp;&emsp;&emsp;通过对样本数据构造模型特征得到模型的输入，模型特征分两类，一类是交叉特征，另一类是原始特征。

&emsp;&emsp;&emsp;交叉特征：选择用户的类别特征、选择物品的类别特征、场景ID做三个维度的交叉，例如：用户历史点击记录为：item1,item2，物品的ID特征为：I1，场景特征为：scene1，那么生成的交叉特征为：item1&I1&scene1，item2&I1&scene1。

&emsp;&emsp;&emsp;原始特征：原始特征是指直接把画像特征作为模型的输入特征，一般是把物品的泛化特征作为原始特征，用于物品冷启动特征或场景冷启动特征，例如：物品的CTR、物品的热度、物品的标签等等。

![avatar](https://img2018.cnblogs.com/blog/1522247/201908/1522247-20190811095457091-1786191676.png)

* Step6：模型训练

&emsp;&emsp;&emsp;把模型中的所有特征进行one-hot编码，假设模型特征数为N，首先给每个模型特征一个唯一1-N的编码，那么每个样本的模型输入向量是维度为N取值0/1的向量，0表示该样本具备对应编号的特征，1表示没有，例如：样本1的具有有编号为 1 和编号为 3 的特征，那么样本1的模型输入向量为 $(1, \, 0, \, 1, \, 0, \, 0, \, \ldots)$，然后通过通用的LR训练器训练模型，即可把模型的参数训练出来。

* Step7：模型使用

&emsp;&emsp;&emsp;给定一个用户u，及一批候选物品，对用户u如何推荐物品。通过上述方法计算用户u对候选集中每个物品的模型得分，按照模型得分降序推荐给用户。

# 深度学习基础知识介绍

本章会介绍各自常用的网络结构，以及模型训练过程中常用的方法

## MLP网络 

MLP网络是一种应用最为广泛的一种网络，其中DNN就是属于MLP网络，它是一个前向结构的人工神经网络，输入一组向量向前传播输出向量，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/4389149045b742d5b24660581b3b4a28.jpeg)

各个层级关系：$a^L = \sigma(z^L) = \sigma(W^L a^{L-1} + b^L)$

其中 $\sigma$ 表示激活函数，集中常见的激活函数有：sigmod函数，tanh函数，ReLU函数。

* sigmod函数：$\sigma(x) = \frac{1}{1 + e^{-x}}$

* tanh函数：$tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$

* ReLu函数：$ReLu(x) = max(0, x)$

## RNN网络

RNN是一种节点定向连接成环的人工神经网络，与DNN网络相比，RNN可以利用上一个时序的输出及当前输入计算输出，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/1d12a5351e7247359463649187cbde90.webp)

展开如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/79feb90ec82f4a559e76e2aec8569201.webp)

各层关系：$ h^{(t)} = \sigma(z^{(t)}) = \sigma(Ux^{(t)} + Wh^{(t-1)} + b) $

## CNN网络

卷积神经网络，是一种前馈神经网络，通过卷积操作可以对一个连续区域进行识别，在图像处理取得不错效果。卷积神经网络的结构有原始图像输入层、卷积层、池化层、全连接层、输出层。网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/4a5622b35f4c4acea75e2304a32f85c5.webp)

之间的连接关系如下：

* 输入层X与卷积层C的关系:

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/7531c99d8b8c4801b8635009958000ce.webp)

* 卷积层C与采样层S的关系:

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/3c1894be53674aacb6e8d90c6f7548a2.webp)

* 采样层S与输出层Y的关系:

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/abb3b26e21ad46ce9d4bd631507ca3a1.webp)

其中 $K \, = \, \{ k_{m,n} \}$

## AE网络

AE自编码器，属于无监督网络。自编码器的目的是输入X与输出X’尽可能接近，网络结构为两层的MLP，这种接近程度通过重构误差表示，误差的函数有均方差和交叉熵，为了保证网络的稀疏性误差函数加L1正则项，为了保证网络的鲁棒性输入增加随机噪声数据。网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/410ca5d4231a415bbefbd301bf8a9570.webp)

## RBM网络

Restricted Boltzmann Machine（受限波尔兹曼机）RBM是无监督的网络。具有两层结构、对称连接且无自反馈的随机神经网络模型，层间全连接，层内无连接。RBM是一种有效的特征提取方法，用于初始化前馈神经网络可明显提高泛化能力，堆叠多个RBM组成的深度信念网络（DBN）能提取更抽象的特征。网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/38e61ac9db9549afb5eae5b7911a43d1.webp)

RBM网络参数的训练原理较为复杂，简单来讲就是求网络的能量函数最小时对应的参数。

## 深度学习与传统模型融合

深度学习与传统模型融合，例如：利用wide&deep就是MLP结合LR的模型，根据模型的训练方式融合模型可以分为松耦合模型和紧耦合模型。

* 松耦合模型：模型的不同部分是独自训练，例如FNN模型就是预先训练好embedding层参数，然后在训练MLP参数。

* 紧耦合模型：模型的不同部分是一起训练的，这类模型也可以称为end-to-end模型，例如wide&deep就是LR模型的参数和MLP的参数是一起训练的。

两种方式各有利弊，松耦合模型的优势是可以灵活组装，紧耦合模型的优势是通过联合在一起训练得到整体效果最优的参数。

# 深度学习常见的损失函数

常用的损失损失函数有两种：交叉熵损失函数、均方差损失函数

（1）交叉熵损失函数：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/f304d2bd88a245a9898bea4538214b26.webp)

（2）均方差损失函数：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/2d472149885d49d4b8a8ae959693dbcb.webp)

## 梯度下降法

在机器学习的许多算法的模型求解过程中，都是通过构造损失函数，然后求解损失函数最小时对应的参数作为模型的解。梯度函数的求解过程如下：

* 第1步：把模型所有参数统一记到一个集合，不妨记为 $\theta = \{ \theta_i \}$，随机给定一组在0-1之间，设为 $\theta^{(0)}$，初始化迭代步数 k=0。

* 第2步：迭代计算

$$ \theta_i^{k+1} = \theta_i^k - \rho \cdot \frac{\partial loss(\theta)}{\partial \theta_i}|_{\theta = \theta^{(k)}} $$

&emsp;&emsp;&emsp;其中用于控制收敛速度，取0.01。

* 第3步，判断是否收敛，如果满足下列两个条件之一则返回 $\theta^{k+1}$，两个条件分别为：  
  * 条件1：$k \geq iterNums$，其中iterNums是最大迭代次数。
  * 条件2：\sum_{i=1}^{dim(\theta)} \: \| \frac{\partial loss(\theta)}{\partial \theta_i} \| \: \lt \: dim(\theta) \cdot \alpha，其中 $dim(\theta)$ 是参数的数量，$\alpha$ 是一个很小的值，可以取 $\alpha = 0.01 \cdot \rho$。

# 深度学习推荐算法的介绍

在本章中，我们挑选了一些业界有影响力会议、期刊的深度学习推荐算法进行介绍。

## FM模型

FM模型是由Steffen Rendle于2010年提出的一种方法，模型的公式如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/481df69847c344aeb118815eca5d63d1.webp)

网络结构：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/d1f4eb21fcbd47cfb1c2583951ad084c.webp)

FM模型是在LR模型的基础上，增加不同特征之间的交叉项，交叉项的向量可以理解为对特征的embedding，简单来讲就是把特征映射到一个多维空间，所有特征的关系可以表示为多维空间中不同向量的关系。

## FNN模型

网络结构：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/6d329bd3d0f84df49fa394e273386295.webp)

FNN模型是FM+MLP的一种模型。Dense Real Layer层，可以理解为embedding层，每个节点代表FM模型的一个参数，然后后面接一个MLP网络。

在训练FNN模型的时候，预先训练Dense Real Layer层，训练的方法和FM模型的训练方法一致。后面在训练MLP参数。由于FNN模型FM和MLP是分开训练的，因此该模型是松耦合模型。

## PNN模型

网络结构：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/a5943e2f6ff94f309faaa4b3a517517f.webp)

PNN模型是在FNN模型的基础上，在FM层与MLP层中间加上一层 Product Layer 层，该层的作用是增加不同field的embedding向量交叉（主要的目的是考虑不同特征组合）。

Product Layer层中，z 部分类似FNN模型的 Dense Real Layer 层，p 部分是不同 field 的 embedding 向量两两交叉值。

## wide&deep模型

网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/4dc0b84e12b14b4abf7ec532a2bfd6e0.webp)

Wide&deep模型是 MLP + LR 的一种模型，LR部分是各种ID类特征的交叉。MLP部分是首先对用户和物品进行embedding，然后接一个MLP模型。模型如下：

$$ P(Y=1 | X) \: = \: \sigma(w_{wide}^T [x, \: \phi(x)] + w_{deep}^T a^{l_f} + b) $$

由于在训练模型的时候LR部分的参数和MLP部分的参数是一起训练的，因此该模型是紧耦合的模型。

## deepFM模型

网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/04c76371be5740459ff5f62a64a73f37.webp)

DeepFM模型与wide&deep相比，是将LR部分改为FM，与LR相比，FM的优点在于自动做特征交叉，减少人工特征工程的工作量。模型计算公式：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/091525f8aafe4d798e7e7c93584ba0a7.webp)

## NFM模型

NFM模型也是一种融合模型，它是由LR + FM + MLP的模型，融合模型分为两部分，一部分是线性模型部分，另一部分是深度学习网络部分，模型公式如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/b3cf499fbbee4035963c2c8da2f09336.webp）

深度学习 f(x) 的结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/492a08791e574b32909a13bdfc566751.webp）

* 其中embedding层：

$$ \nu_{x} = \{ x_i v_i \} \: \: where \: \, x_i \neq 0 $$

&emsp;&emsp;&emsp;$\{V_i\}$ 是需要学习的模型参数。

* $B_i$ 层是两两embedding向量交叉，然后求和，公式如下，

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/0c49064cbff64739909d70ae8e6b841d.webp)

&emsp;&emsp;&emsp;$B_i$ 层后面就是MLP网络。

## AFM模型

AFM是在NFM上，引入attention机制，简单来说就是把NFM的Bi层直接求和改进为加权求和，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/3d6aa05c54104ce88c2dad017370bc8f.webp)

改进后的 $B_i$ 层公式如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/515dfb9c23ff418da261e517757ca5d1.webp)

其中 $a_{i,j}$ 是需要训练的attention权重，$a_{i,j}$ 的节点是embedding层接一个ReLU层，然后在做归一化，表达式如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/1a3e3b264d344264898972fa84904269.webp)

## DSSM模型

DSSM模型是MLP + cosine的一个融合算法，该模型主要是运用在搜索场景里面的请求（query）与点击物品（document），首先模型将请求/物品分别运用MLP网络进行特征学习，然后运用余弦值衡量请求对物品的相关性，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/a5effd1a300746818c13b73f8d8e95f5.webp)

损失函数的定义过程如下：

* 首先定义请求与物品的相关性：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/8ef9c3e310b14f5eac922e0219c882b1.webp)

* 然后对请求与不同物品相关性进行标准化处理：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/0f1d2e50be3a4b1bb10c6a0a987ca8b5.webp)

损失函数定义为：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/8ef9c3e310b14f5eac922e0219c882b1.webp)

其中损失函数只取用户对物品有点击过的样本（只取正样本），该损失函数对一个Q（请求）训练一次（不同query的MLP网络参数不一样）

## MV-DNN模型

MV-DNN是在DSSM上面进行改进，DSSM中所有物品都用同一个MLP网络结构及参数，而MV-DNN则是一个物品一个网络，由于一个物品一个MLP网络该模型取名为“多视角的DNN模型”，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/ddb7b96ba2214f78a002d690618778c7.webp)

损失函数的定义与DSSM类似：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/7d79f987b73b42cd988d01567cb56900.webp)

## DCN模型

该模型首先会有一个embedding层，然后并行接入Deep网络和一个CROSS网络，最后合并两个网络的输出接一个sigmoid层作为最终输出，结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/49c7e9c34c2a49b1aa4778b9704db700.webp)

网络结构embedding层主要做的工作就是把稀疏且维度高（一般是特征的one-hot编码）的输入转化为稠密且维度低的向量（低维实数向量），转化通过一个embedding矩阵参数完成，如：

$$ x_{embed,i} = W_{embed,i} x_i $$

* Deep网络是一个MLP网络。

* CROSS网络有点类似MLP网络，在MLP网络的基础上，每个层都会与输入的embedding层做交叉，公式如下：

$$ x_{l+1} = x_0 x_l^T w_l + b_l + x_l $$

模型的训练：embedding层参数和cross网络参数及deep网络参数，及sigmoid层参数都是一起训练的。

## NCF模型

NCF模型简单来讲就是 embedding + MLP 网络。模型首先会把用户输入和物品输入分开，并且分别接一层embedding，然后合并两个embedding层作为MLP网络的输入

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/08232a128eb24742a4fa1ba6d7f2f4aa.webp)

## GBDT+LR模型

GBDT+LR算法最早是由Facebook在2014年提出的一个推荐算法，该算法分两部分构成，第一部分是GBDT，另一部分是LR.下面先介绍GBDT算法，然后介绍如何将GBDT和LR算法融合

### GBDT算法

GBDT是Boost的一种典型算法，Boost的原理：首先对样本集进行训练得到第一个模型，然后对模型分类错误的样本进行提权得到新的样本集，在新的样本集上进行训练得到第二个模型，如此类推得到n个预测模型。预测的时候通过每个模型的预测值进行加权，模型的权重可以用模型的准确率衡量

GBDT算法首先对训练样本建立一颗决策树，然后每个样本的目标变量调整为第一颗决策树预测值与实际值的残差，得到一个新的训练样本，在新的训练样本下建立第二课决策树，依次类推得到m颗决策树。详细构造如下：

* Step1：数据准备

&emsp;&emsp;&emsp;设原始的训练样本为:

$$ \{ (x_1, y_1), \: (x_2, y_2), \: \ldots \: (x_n, y_n) \} $$

* Step2：生成第1颗决策树

&emsp;&emsp;&emsp;运用CART算法，对原始样本生成1颗决策树，第1颗决策树定义为，表示第1颗决策树对样本的预测值

* Step3：生成第2颗决策树

&emsp;&emsp;&emsp;构造第2颗决策树的训练样本数据，对每个样本的目标变量用残差表示，具体如下：

$$ \{ (x_1, y_1 - DT_1(x_1)), \: (x_2, y_2 - DT_1(x_2)), \: \ldots \: (x_n, y_n - DT_1(x_n)) \} $$

&emsp;&emsp;&emsp;同样运用CART算法生成第2课决策树，第2颗决策树定义为 $DT_2$，$DT_2(X_i)$ 表示第2颗决策树对样本 $X_i$ 的预测值

* Step4：生成第m颗决策树

&emsp;&emsp;&emsp;构造第m颗决策树的训练样本数据如下：

$$ \{ (x_1, DT_{m-2}(x_1) - DT_{m-1}(x_1)), \: (x_2, DT_{m-2}(x_2) - DT_{m-1}(x_2)), \: \ldots \: (x_n, DT_{m-2}(x_n) - DT_{m-1}(x_n)) \} $$

&emsp;&emsp;&emsp;运用CART算法生成第 m 课决策树，第 m 颗决策树定义为 $DT_m$，$DT_m(X_i)$ 表示第 m 颗决策树对样本 $X_i$ 的预测值

&emsp;&emsp;&emsp;预测的时候，将每一颗决策树的预测结果加起来就是GBDT模型的预测值。

### GBDT与LR融合的算法

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/08c1e08f6a74469b9c7abb4d75fb2863.webp)

Facebook提出来的论文当中，把样本在GBDT模型中决策树的叶子节点作为样本的特征，输入到LR模型里面。简单理解就是让GBDT模型来做特征工程。

### 扩展

沿着上述算法的思路，我们可以将one-hot离散化特征，以及BP模型融合到与GBDT并行的一层，在外面在接一层LR算法。这里面并行的模块有GBDT、one-hot离散化特征、BP，可以理解为3种不同方法的特征工程，结构图如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/fe9e4bad0b0343c08f31282f62844e14.webp)

## seq2seq模型

seq2seq模型是由谷歌在2014年提出的一种模型，它由一系列的LSTM构成的模型，而LSTM是RNN的一种变种，RNN前面我们已经介绍了，下面我们先介绍LSTM，在介绍seq2seq模型。

### LSTM模型

（1）LSTM模型网络结构

&emsp;&emsp;&emsp;LSTM是RNN的一种改进网络，单层LSTM网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/a0b49c19f3674f87b402eb423b5bbec7.webp)

&emsp;&emsp;&emsp;设用 $X_t$ 表示 LSTM 输入向量，$h_t$ 表示 LSTM 的输出值，$C_t$ 表示 LSTM 的状态向量。LSTM 模型可以看作是由两个主要两个函数构成的网络，第一个是用于计算记忆向量 $C_t$ 的函数，另一个是用于计算输出向量 $h_t$ 的函数。

&emsp;&emsp;&emsp;用于计算状态向量 $C_t$ 的函数定义如下，它依赖的向量有3个，分别为前一个输入得到的状态向量 $C_{t-1}$ 及输出向量 $h_{t-1}$，和当前输入向量 $X_t$。

$$ C_t = LSTMC(C_{t-1}, \: h_{t-1}, \: X_t) $$

&emsp;&emsp;&emsp;用于计算输出向量 $h_t$ 的函数定义如下，它同样依赖 $C_{t-1}、h_{t-1}、X_t$。

$$ h_t = LSTMh(C_{t-1}, \: h_{t-1}, \: X_t) $$

（2）LSTM内部逻辑

&emsp;&emsp;&emsp;如上图，我们队LSTM内部的计算做了红色标记，总共有9次计算，每次计算的公式如下：

&emsp;&emsp;&emsp;第1次计算：

$$ f_t = \sigma(W_f[h_{t-1}, X_t] + b_f) $$

&emsp;&emsp;&emsp;&emsp;其中 $\sigma$ 是sigmod函数：$\sigma(x) = \frac{1}{1+e^{-x}}$，$W_f$ 和 $b_f$ 是模型参数，$f_t$ 是 0 到 1 之间的实数。

&emsp;&emsp;&emsp;第2次计算：

$$ C_{t-1}^{'} = f_t * C_{t-1} $$

&emsp;&emsp;&emsp;&emsp;其中 $C_{t-1}$ 是上一个输入的状态向量

&emsp;&emsp;&emsp;第3次计算：

$$ i_t = \sigma(w_i[h_{t-1}, \: X_t] + b_i)$$

&emsp;&emsp;&emsp;&emsp;其中 $W_i$ 和 $b_i$ 是模型参数，$i_t$ 是 0 到 1 之间的实数。

&emsp;&emsp;&emsp;第4次计算：

$$ \hat{C_t} = tanh(W_C[h_{t-1}, \: X_t] + b_C)$$

&emsp;&emsp;&emsp;&emsp;其中 $W_C$ 和 $b_C$ 是模型参数，tanh是双曲正切函数，表达式为：$tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$

&emsp;&emsp;&emsp;第5次计算：

$$ \hat{C_t^{'}} = i_t * \hat{C_t}$$

&emsp;&emsp;&emsp;第6次计算：

$$ C_t = C_{t-1}^{'} + \hat{C_t^{'}}$$

&emsp;&emsp;&emsp;第7次计算：

$$ \sigma_t = \simga(W_o[h_{t-1}, \:  X_t] + b_o)$$

&emsp;&emsp;&emsp;第8次计算：

$$ g_t = tanh(C_t) $$

&emsp;&emsp;&emsp;第9次计算：

$$ h_t = o_t * g_t $$

（3）LSTM的使用

&emsp;&emsp;&emsp;LSTM模型使用，首先把所有事件按照顺序排列成一个序列，逐个输入到LSTM模型，通过状态向量 $C_{t-1}$ 使模型记忆和理解上下文，例如：用户输入一串字符ABC，预测用户下一个输入，把A、B、C进行one-hot向量化，得到 $X_1,X_2,X_3$，依次带入计算：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/31a33c0a61f64dd68b699766b59c9d39.webp)

&emsp;&emsp;&emsp;&emsp;其中 $C_0,\: h_0$ 为初始化向量。

### seq2seq

模型结构图如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/216d64168ef642528ded12c28b637564.webp)

上图中左边为输入ABC，后边为输出WXYZ，整个模型分为左右两个LSTM网络，左边为encoder的LSTM网络，右边为decoder的LSTM网络。在谷歌发表的论文中，他们采用的是4层的LSTM网络。

为了便于说明，我们以单层LSTM的seq2seq模型为例，模型展开如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/cce8851cced646d588ead161e998c822.webp)

其中Input每个输入的LSTM网络参数都是一样，同理output的每个输出的LSTM网络参数是一样的。ENCODER的输入是one-hot编码的词，DECODER输出的是one-hot编码的词。

### 如何将seq2seq运用到推荐算法

seq2seq模型的优点，序列化预测，一个输入序列输出一个序列。在推荐场景中可以将用户历史浏览的物品按照时间顺序排列形成输入序列，将用户在输入节点后的物品浏览记录按照时间顺序形成输出序列，然后运用seq2seq算法进行预测

## DNN在youtube应用

论文见DNN-YouTube.pdf。在该模型中，首先会用一个MLP网络对用户进行特征抽取得到向量u，然后与视频的向量相乘做归一化作为输出，网络结构如下：

![avatar](http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20190113/b1e464f99dcf4fe281f3199bcc76407b.webp)

其中视频的embedding该论文只是一笔带过（把稀疏实数向量映射到低维的稠密向量），实际上可以embedding的方法根据目标函数的不同及模型的不同分为很多种，例如：FM模型，W2V模型都可以用来做embedding的方法。

Deep网络把用户的历史观看视频记录、搜索记录、地理位置embedding后、及用户社会属性联合起来作为Deep模型的输入MLP模型的输入。
