---
title: 深度树匹配推荐技术-TDMopt
date: 2018-11-26
categories: 计算广告
tags:
- 计算广告
- Matching
---

# 背景

如下图所示，在大规模任务中，搜索，推荐和广告的系统通常由模型，索引和检索算法三大组件组成。模型计算单个用户-对象的偏好概率，索引将所有商品有序地组织在一起，检索算法根据模型的输出在索引中召回最终的推荐结果。三者共同决定了召回质量且存在内在联系。

<!-- more -->

![avatar](/images/计算广告/ad-28.png)

然而，以推荐为例，现有的推荐体系对模型索引和检索的相互联系往往没有做充分的考量。从联合调优这一视角出发，现有的几代推荐体系的代表算法存在问题分析如下：

* 在经典的Item-CF中，倒排索引根据item之间某种自定义的相似度量建立，检索过程则是根据用户历史行为在倒排索引中查询候选集后排序截断，模型在排序过程中对候选集中的Item根据某种自定义的规则进行打分。在系统中，模型和检索被规则固化，没有学习调优。

* 在向量检索的模式中，系统会分别为用户和商品学习一个向量表达，其内积作为用户对商品的偏好程度的预测。检索等价于用户向量在商品向量集合中的kNN最近邻检索，在大规模问题中，可以采用近似的最近邻索引结构来加速检索。在建立向量检索推荐系统的过程中，模型训练的目标是准确的预测单个用户-对象的偏好概率，而kNN检索索引建立的目标则最小化近似误差，二者的优化方向并不一致。同时，内积形式的偏好预测表达能力有限，无法容纳更加先进的打分模型。

* 在TDM中，我们通过交替迭代优化模型和树结构再加之无参数的逐层beam search检索过程进行了模型、索引和检索联合优化上的实践和创新。然而在TDM中，模型的优化和树结构索引的学习二者的优化目标也不完全一致，这可能导致二者的优化相互牵制而导致最终整体效果次优。特别是对于树结构索引，模型训练样本的构造和检索路径的选择与树结构具有更加紧密的联系。

综上分析，本文在TDM的基础上进一步提出统一目标下联合优化深度模型和树结构索引的大规模推荐算法框架TDMopt(Optimized TDM)。

# 端到端联合学习的深度树匹配推荐技术

TDMopt继承了TDM树结构索引+任意深度用户-商品偏好打分模型的系统框架，通过联合优化和层次化特征建模取得了大幅超越TDM的推荐精度，具有广阔的应用前景，完全具备推广到搜索，广告等相关业务的理由和能力。TDMopt已经在阿里妈妈精准展示广告业务的matching阶段初步落地，在TDM的基础上取得显著效果提升。

## 深度树推荐模型TDM

推荐系统的任务是从候选集(例如，商品库)中选出用户当前偏好的一个子集。当候选集的规模很大时，如何快速有效地从全库中做推荐是一个具有挑战性的问题。之前介绍的深度树匹配推荐技术创造性地采用树结构作为索引结构并进一步地令用户对树上节点的偏好满足下面的近似最大堆性质：

$$ p^{l}(n|u) = \frac{max_{n_c \, \in \, {(n's \, children \, nodes \, in \, level \, j + 1)}} \: p^{j+1}(n_c | u)} {\alpha^{(l)}} $$

其中 $p^{l}(n\|u)$ 是用户 $u$ 对节点 $n$ 偏好概率的真值，$\alpha^{(l)}$ 是第 $l$ 层内偏好概率分布的归一化项。这样的建模保证了第 $l$ 层节点中偏好概率最大的 $k$ 个节点一定包含在第 $l - 1$ 层的top-k节点的子节点中。基于这一建模，TDM将推荐问题转换为树结构中自上而下的层次化的检索问题。下图给出了TDM候选子集的生成过程。

![avatar](/images/计算广告/ad-29.png)

首先，候选集中的每个对象(例如，一个商品或者广告)都被分配到树的一个不同叶子节点上，如右图所示。树上的非叶子节点可以看做是它的子节点集合的一个抽象。左图给出了用户对节点的偏好概率的计算过程，用户信息和待打分的节点首先被向量化为深度打分网络(例如，全连接网络，attention网络等等)的输入，网络的输出作为用户对该节点的偏好概率。在检索top-k的候选子集即top-k叶子节点的过程中，我们采用自顶向下的逐层beam search方法。在第 $l$ 层中，我们只对第 $l - 1$ 层被选中的 $k$ 个节点的子节点进行打分和排序来选择第 $l$ 层的 $k$ 个候选。右图给出了检索过程的示意。

通过采用树结构作为索引，对一个用户的偏好子集进行top1检索的时间复杂度为 $O(log(N))$，其中 N 为全部候选集的大小。这一复杂度也与用户偏好打分模型的结构无关。同时，近似最大堆的假设将模型学习的目标转化为用户-节点偏好分布的学习，这使得TDM能够打破最近邻检索模式带来的内积形式的用户偏好打分的限制，赋能任意复杂打分模型，从而极大的提升了推荐的准确率。

## TDMopt中的联合优化框架

从检索过程中可以看到，TDM的推荐准确率由用户偏好打分模型 $\mathcal{M}$ 和树索引结构 $\mathcal{T}$ 同决定且二者相互耦合。具体地，给定 n 对正样本 $(u_i, c_i)$，即用户 $u_i$ 对对象 $c_i$ 感兴趣，树结构 $\mathcal{T}$ 决定了模型 $\mathcal{M}$ 需要选择哪些非叶子节点来对用户 $u_i$ 返回对象 $c_i$。在统一目标下联合优化 $\mathcal{M}$ 和 $\mathcal{T}$ 能够避免二者优化方向的冲突造成的整体结果次优。

记 $p \left( \pi(c_i)) \vert u_i;\pi \right)$ 为用户 $u_i$ 对叶子节点 $\pi(c_i)$ 的偏好概率，其中 $\pi (\cdot)$ 是把候选集中的对象投射到树的叶子节点上的投影函数。$\pi(c_i)$ 决定了候选集中的对象在树结构上的索引顺序。如果 $(u_i, c_i)$ 是一个正样本，我们有 $p \left( \pi(c_i)) \vert u_i;\pi \right) = 1$。 同时在近似最大堆的假设下，对 $\pi(c_i)$ 的所有祖先节点 $\\{p ( b_j (\pi(c_i)) \vert u_i; \pi) \\}_{j=0}^{l_{max}}$，其偏好概率也为 1。其中 $b_j (\cdot)$ 是把一个节点投影到其在第 $j$ 层的祖先节点的投影函数，$l_{max}$ 为树 $\mathcal{T}$ 的层数。记 $ \hat p \left( \pi(c_i)) \vert u_i;\theta,\pi \right)$ 为模型 $\mathcal{M}$ 返回的用户 $u_i$ 对节点 $\pi(c_i)$ 的偏好概率的估计值，其中 $\theta$ 为模型的参数。给定 n 对正样本 $(u_i, c_i)$，我们希望联合优化 $\pi$ 和 $\theta$ 来拟合上述的用户对树上节点的偏好分布。为此，我们希望 $\pi$ 和 $\theta$ 最小化如下的全局经验损失函数：

$$ \mathcal{L}(\theta,\pi) = -\sum_{i=1}^n \sum_{j=0}^{l_{max}} \log \hat p \left( b_j (\pi(c_i)) \vert u_i;\theta,\pi \right) $$

在求解中，由于优化 $\pi$ 是一个组合优化问题，很难和 $\theta$ 用基于梯度的优化算法同时优化。因此，我们提出交替优化  $\pi$ 和 $\theta$ 的联合优化框架，如下图所示。优化  $\pi$ 和 $\theta$ 的目标一致性促进了整个算法的收敛。事实上，如果模型学习和树学习能够同时使得损失函数下降，那么整个算法一定会收敛，因为 $\{ \mathcal{L}(\theta_t,\pi_t) \}$ 是下界为0的单调下降序列。

![avatar](/images/计算广告/ad-30.png)

在模型训练中，$\min_\theta \mathcal{L}(\theta, \pi)$ 是为了求解得到每层的用户-节点偏好打分模型。得益于树结构和近似最大堆的性质，我们只需要在模型训练中拟合训练集中的用户-节点偏好分布，这使得我们可以使用任意复杂的神经网络模型，同时 $\min_\theta \mathcal{L}(\theta, \pi)$ 可以用流行的算法例如SGD,Adam求解。采样策略如Noise-contrastive estimation(NCE)可以用来加速计算 $\hat p \left( \pi(c_i)) \vert u_i;\theta,\pi \right)$ 中的归一化项。

树结构学习是在给定模型参数的情况下求解 $\min_\theta \mathcal{L}(\theta, \pi)$，这是一个组合优化问题。事实上，给定树的形状时(为了便于表达，我们假定树的形状是完整二叉树。我们提出的优化算法可以方便地推广到多叉树的情况)，$\min_\theta \mathcal{L}(\theta, \pi)$ 等价于寻找候选集和所有叶子节点之间的一个最优匹配，这进一步等价于一个带权二部图的最大匹配。分析过程如下：

若第 k 个对象 $c_k$ 被分配到第 m 个叶子节点 $n_m$上，即 $\pi(c_k)=n_m$，我们可以计算如下的权重：

$$ \mathcal{L}_{c_k,n_m} = \sum_{(u,c) \in \mathcal{A}_{k}}\sum_{j=0}^{l_{max}} \log \hat p \left( b_j(\pi(c))\vert u; \theta,\pi \right) $$

其中 $\mathcal{A}_ k$ 包含了所有目标对象 c 为 $c_k$ 的正样本对 $(u, c)$。把树的叶子节点和候选集作为顶点，叶子节点和候选集之间的全连接作为边，把 $\mathcal{L}_{c_k,n_ m}$ 作为 $c_k$ 和 $n_m$ 之间边的权重，我们可以构造一个带权二部图 $V$ ，如2.1节的流程图(b)所示。在这种情况下，每个可能的 $\pi (\cdot)$ 都是 V 的一个匹配，同时我们有

$$ \mathcal{L}\left(\theta,\pi \right) = -\sum_{i=1}^{|\mathcal{C}|} \mathcal{L}_{c_i,\pi(c_ i)} $$

$\mathcal{C}$ 为所有 $c_i$ 的集合。因此，$\min_\theta \mathcal{L}(\theta, \pi)$ 等价于求解 V 的最大权匹配。

对于大规模的候选集，传统的求解最大权匹配的算法例如匈牙利算法由于复杂度太高而难以使用。即使是最简单的贪婪算法，计算和存储所有的权重的成本也是无法接受的。为解决这一问题，我们利用树结构提出了一种分段式树学习算法。相比于直接将所有对象分配到叶子节点中，我们在树上自上而下的每 d 层做一次分配。记

$$ \mathcal{L}_{c_k,\pi(c_k)}^{s,t} = \sum_{(u,c)\in \mathcal{A}_k}\sum_{j=s}^{t} \log \hat p \left( b_j(\pi(c_k))\vert u; \theta,\pi \right) $$

为 $\mathcal{L}_{c_k,\pi(c_k)}$ 从第 s 层到第 t 层的部分权重。在算法中，我们首先通过最大化 $\sum_{i=1}^{|\mathcal{C}|} \mathcal{L}_{c_i,\pi(c_ i)}^{1, d}$ 来将候选集分配到第d层的所有节点上。对于一个完整二叉树来说，每个第 d 层的节点应该包含不超过 $2^{l_{max}-d}$ 个对象。这也是一个最大权匹配问题并可以通过贪婪算法有效求解，因为每个对象可能的分配位置被大大减少了(例如对于 $d = 7$，只有 $2^d = 128$ 个可能的位置)。在保持每个对象在第d层的祖先节点不变的前提下，我们将候选集在接下来的d层中继续分配直至每个对象被分配到叶子节点上。整个算法的流程如下：

![avatar](/images/计算广告/ad-31.png)

在第5行中，我们用一个平衡的贪婪算法来求解每个子问题。每个对象 $c \in \mathcal{C}_{n_ i}$ 首先根据权重 $\mathcal{L}_ {c,\cdot}^{l-d+1, l}$ 分配到
 $n_i$ 在 $l$ 层的某个子节点中。为保证每个 $l$ 层的子节点含有不超过 $2^{l_{max}-l}$ 个对象，需要对贪婪分配的结果进行平衡。为促进树学习和整个框架的收敛，对含有多于 $2^{l_{max}-l}$ 个对象的节点，我们优先保持在上轮迭代中就在同一位置的对象不动，然后对其他对象按照权重大小排序，将超出 $2^{l_{max}-l}$ 的部分对象根据权重移动到其他不足  $2^{l_{max}-l}$ 的节点中。我们提出的树学习算法使得我们不需要存储一个巨大的权重矩阵，而且每层的子学习任务可以并行化以进一步提高效率。
 
## 层次化用户特征建模

本质上，TDMopt(和TDM)是对以倒排索引+相关性检索这种沿袭自搜索引擎架构的广告匹配/排序体系的深度改造。树结构的每一层可以看做是商品不同粒度上的倒排索引，TDM和TDMopt通过树上自顶向下的逐层相关性检索，从粗到细地找到用户信息匹配的最佳候选子集，这也与人类视角选择偏好商品的过程相契合。通过联合考虑模型和索引结构，TDM和TDMopt将一个复杂的大规模推荐任务分解为若干个级联的子检索任务，在上层的检索任务中，我们只需要在一个更粗的粒度上做圈选，且每层圈选的候选集远小于候选集全集，其训练难度将大大缩小。可以预见，当子检索任务的解足够理想时，其级联后的检索结果将超越直接在候选集中圈选候选集的效果。
 
事实上，树结构本身提供了候选集的一个层次结构，因为每个非叶子节点都是其所有子节点的一个学习到的抽象，这启发我们在训练模型 $\mathcal{M}$ 做每层的子检索任务时对用户行为特征做最利于模型学习的精准层次建模。具体而言，用户历史行为的每个对象都是一个ID类离散特征，在模型训练中，每个对象和树上的节点都被嵌入到一个连续特征空间并与模型同时优化。从每个非叶子节点是其子节点的抽象这一点出发，给定用户行为序列 $c = \{ c_{1}, c_{2},\cdots ,c_{m} \}$，我们提出用 $c^l = \{ b_l(\pi(c_{1})), b_l(\pi(c_{2})),\cdots, b_l(\pi(c_{m})) \}$  联合目标节点以及用户的其他特征来生成模型 $\mathcal{M}$ 在第 $l$ 层检索的输入。通过这种方式，用户行为过的对象在第 $l$ 层的祖先节点被用作了用户抽象化的行为序列。这主要带来了两方面的好处：

* **层间的独立性**：传统的在每层检索中共用用户行为序列的embedding会在训练 $\mathcal{M}$ 作为每层的用户偏好打分模型时引入噪声，这是因为 $\mathcal{M}$ 在每层的训练目标是不同的。一个直接的解决办法是在每层赋予每个对象一个单独的embedding来联合训练。但是这会极大的增加参数量。我们提出的层次化用户行为特征使用对应层节点的embedding生成 $\mathcal{M}$ 的输入，从而在没有增加参数总量的同时实现了层间embedding学习的独立。

* **用户的精准建模**：$\mathcal{M}$ 在检索过程中逐层选择最终候选子集的从粗到细的抽象。我们提出的层次化用户行为特征表达抓住了这一检索过程的本质，用当前层的节点对用户行为进行了适当的抽象，从而增加了用户偏好的可预测性，减少了过粗或者过细的特征表达带来的混淆。

# 实验

我们使用了Amazon Books和UserBehavior两个大型公开数据集来进行方法的效果评估。Amazon Books是用户在Amazon上的行为记录，我们选择了其中最大的Books这一子类目。UserBehavior为阿里开源的淘宝用户行为数据集。数据集的规模如下：

![avatar](https://upload-images.jianshu.io/upload_images/6881750-72db4b7cc6f8a280?imageMogr2/auto-orient/strip|imageView2/2/w/1080/format/webp)

在实验中，我们比较了下面几种方法：

* Item-CF: 基本的协同滤波算法，被广泛应用于个性化推荐任务中。  
* YouTube product-DNN: 应用于Youtube视频推荐的向量内积检索模型。  
* HSM: 层次Softmax模型，被广泛应用于NLP领域，作为归一化概率计算的一种替代.  
* TDM： 我们此前的工作深度树匹配推荐技术。  
* DNN: TDM模型去掉树结构后的版本。该方法不使用索引结构，在预测时会对全量候选集进行打分，再挑选topk。由于对全量候选集打分的计算复杂度非常高，因此无法实际应用，但可以作为强baseline来进行比较。  
* TDMopt: 本文中提出的联合优化方法。同时，我们对比了JTM的两个变种版本，分别为JTM-J和JTM-H。其中，JTM-J为使用了树结构联合优化但没有采用层次化用户兴趣表达的版本；JTM-H相反，其使用了层次化用户兴趣表达，但会使用固定的初始树结构而不进行联合学习。

在所有神经网络模型中，均使用相同的三层全连接网络作为打分模型。把用户的行为序列的embedding进行拼接作为网络的输入。TDM和TDMopt需要一个初始的树结构作为索引，在Amazon Book数据集上，我们使用随机挂载的树初始化。在UserBehavior数据上，我们将来自相同类目的商品挂载在相邻的叶子节点上生成一个类目树初始化。我们使用Precision, Recall和F-measure作为性能评测指标，定义如下：

![avatar](https://upload-images.jianshu.io/upload_images/6881750-ea4534df2cf9a0a6?imageMogr2/auto-orient/strip|imageView2/2/w/1080/format/webp)

# 参考

[1]. <https://www.jianshu.com/p/49f5707fdf5e>



