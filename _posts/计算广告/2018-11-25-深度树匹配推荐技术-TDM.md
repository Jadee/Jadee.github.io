---
title: 深度树匹配推荐技术-TDM
date: 2018-11-25
categories: 计算广告
tags:
- 计算广告
- Matching
---

# 背景

推荐、搜索、广告投放是互联网内容提供商进行流量分配的核心业务，也是大数据和机器学习技术的典型应用场景。无论是推荐，搜索，还是广告投放问题，都可以描述为从大规模候选中给用户提供有限的展现结果以获取用户的正向反馈（广告投放还需额外考虑广告主意愿和体验）。在具体实现中，由于在线业务对性能尤其是响应时间的严格要求，我们往往会把上述过程拆分为两个阶段——**匹配（Match）+ 排序（Rank）**。

以淘宝推荐系统为例，匹配阶段的核心在于如何从全量商品（Item）中根据用户（User）信息召回合适的TopK候选集合，排序阶段则是对TopK候选集合进行精细化打分并排序输出最终展现的结果。排序阶段因为候选集小，可以引入诸如深度学习等非常复杂的模型来优化目标，达到最终效果（相关性、广告收益等）的提升，业界对此阶段的研究比较集中和深入，比如精准广告业务线在排序阶段的CTR预估上引入了基于Attention结构的深度兴趣模型（DIN，详见附录），取得了非常好的业务效果。而匹配阶段由于问题规模大，复杂模型在此阶段的应用存在一定的局限性，所以业界对这方面的研究尤其是深度学习在此阶段的应用仍处在发展阶段。回到上述关于两阶段的描述，可以看出**匹配阶段产生的候选集的质量会成为最终效果的天花板**，因此如何创新和发展匹配技术是对业务有着重大意义的问题，也一直是业界和学术界关注的重点问题。

以推荐为例，在工业级的推荐系统中，匹配阶段往往面临很多技术挑战。例如当候选集非常大的时候，要从全量候选集中挑选TopK集合，我们无法接受随着全量候选集大小而线性增长的时间复杂度，这使得一些学术界研究的需要计算全量 {User，Item} 兴趣度的方法并不能真正应用于实际推荐系统中的匹配阶段。在有限的计算资源下，如何根据用户信息从全量候选集中快速得到高质量的TopK候选集，需要在计算效率和计算准确性上做精巧的平衡。作为真实应用的推荐系统，其匹配阶段的计算时间需要被限制，简单用以下公式表示：

$$ T * N \leq Bound \tag{1} $$

其中 T 表示单次计算的时间消耗，N 可以认为是为单个用户召回 TopK 需要的总体计算次数。在上述公式的约束下，围绕如何提升匹配效果，工业界的技术发展也经历了几代的演进，从最初的基于统计的启发式规则方法，逐渐过渡到基于内积模型的向量检索方法。然而这些方法在技术选型上都在上述计算效率约束下对匹配效果进行了很大的牺牲。如何在匹配阶段的计算效率约束下引入更先进的复杂深度学习模型成为了下一代匹配技术发展的重要方向。

# 相关技术

如上文所述，结合工业级推荐系统的约束，匹配技术经历了从基于统计的启发式规则方法到基于内积模型的向量检索方法的转变，具体描述如下：

## 第一代——基于统计的启发式规则方法

这一类方法的经典代表就是Item-based Collaborative Filtering（Item-CF），也是应用最广的推荐算法之一。Item-CF的算法原理是：首先通过统计计算得到Item to Item（I2I）的相似关系，其次启发式地获取用户近期行为作为 Trigger Item 集合，用它们进行 I2I 扩展，最后以某种打分规则对扩展后的Item集合进行排序，截断得到TopK作为候选集进行后续排序流程。

结合公式（1），我们可以知道这种方法有效的控制了总体计算次数N，因为用户的Trigger Item集合是有限的，相似关系圈定的候选集合也是有限的，从而避免了对全量候选集的计算，同时简单的打分规则可以有效地控制单次计算时间T，两者使得最终整体方法的计算量较少，满足了在线应用的要求。

这种方法在业务初期简单有效（对比非个性化的方式），但从算法原理不难看出，这种方法天然存在一大弊端：它限制了尝试推荐给用户未曾行为过但可能感兴趣的Item的可能性。这种将候选限定在历史兴趣相似范畴内的启发式规则对推荐效果的提升有限，它降低了用户体验（尤其是推荐结果的惊喜度），也制约了系统整体的可持续发展能力。尽管后续的排序环节可以引入复杂的机器学习方法，例如MLR（混合逻辑回归，详见附录），FM（因子分解）或者深度学习，但它们都依赖于匹配给出的候选结果，所以无论如何复杂的模型都突破不了匹配给定的上限。

## 第二代——基于内积模型的向量检索方法

引入机器学习方法来提升匹配能力是业界共识和趋势。机器学习本质上是一个衡量模型，可以衡量用户对商品的兴趣度。这种基于模型的匹配方法理论上要衡量一个用户对所有商品的兴趣度，从而挑选出最优的推荐结果。这就带来了问题：

**对于大规模商品候选集的场景是计算不可行的。如何化解计算不可行的问题？**

研究人员提出了以向量距离的方式衡量用户和商品兴趣度的方法，用户和商品被表示成向量形式，并以此为基础建立基于向量聚类的索引结构进一步加速衡量效率，于是这个计算问题变成了在有限时间内是可解的（近似求解），具体实现也落到了向量引擎的范畴。结合公式（1），T 代表简单的向量内积计算时间，而 N 则通过建立向量索引结构从而控制在 O(桶候选集规模) 的较小范围内。所以内积式模型和向量引擎成为了最近几年匹配领域技术革新的最重要技术（图像检索问题最早就是采用的这种方法）。尤其是去年Facebook的Faiss框架开源，极大降低了业界尝试向量引擎的难度，对行业发展起到了极大的促进作用。至此，基于内积模型的向量检索方法引领了第二代匹配和推荐技术的潮流，在各类学术会议和工业实践中大放异彩。

然而问题是，这类方法并未实现充分利用机器学习解决匹配问题的初衷，对机器学习模型的限制太大。高阶深度学习大部分都不可划成内积形式，比如CTR预估里用户和商品特征交叉非常有用，大部分不可用内积表示。而在现有深度学习中内积模型的表达能力被证明是有限的，比如将内积模型中最后的内积运算直接换成多层感知机能大幅提升模型能力，而多层PNN，DIN（详见附录）等对用户兴趣更有洞察力的复杂模型效果被证明能极大的超越内积模型。

与此同时，我们也发现在具体实践中，向量检索算法要求User和Item能够映射到统一的向量空间。User输入信息和Item输入信息一般并不同质，如何保证映射到统一目标向量空间下的检索精度对映射算法提出了严格的要求，换言之，统一的向量空间映射对运用向量检索来解决推荐问题带来了精度损失的风险。

## 下一代匹配和推荐技术

结合上文的描述，匹配技术发展的核心点在于系统性能限制下尽可能提升兴趣的衡量精度（从规则算法到引入先进模型）和覆盖范围（从限定候选集到全量候选集）。为此对下一代匹配和推荐技术进行研究，自主提出了一种更通用的匹配和推荐算法框架，它允许容纳任意先进模型而非限定内积形式，并且能够对全量候选集进行更好的匹配。无论在公开数据集还是在阿里数据集上，新方法的召回率和新颖性对比前两代技术都有飞跃性的提高。以推荐问题为例进行展开，实验也是在推荐应用的场景下进行的。值得指出的是，匹配问题本身作为推荐、搜索、广告投放业务中的核心模块，使得方法具有很强的普适性。

# 技术方案

承上所述，第二代基于内积模型向量检索的方案，限定模型结构以实现检索效率的提升，因此要想进一步释放模型能力就必须使得整体检索结构的设计与模型结构的设计解耦（向量内积检索与内积模型即是一种强耦合关联）。面对一个复杂问题，人脑常有的一个思考方式是先从大的层面入手，确定大方向后具体细化。因此从这个角度入手，思考是否可以有一种从粗到细的检索方式，逐步判断并细化，最后给出最优推荐。基于这个思考，我们把探索方向定位在了使用层次化树结构增加检索效率上。然而，模糊的上层概念想起来容易，概念上万物皆通，真正难的是否能在数学和技术上构建出一条真正可行的路径。就匹配问题而言，树检索结构的引入伴随着一系列的问题要解决：

1、树结构是如何构建的；  
2，如何基于树进行匹配建模；  
3、如何围绕树结构实现高效的兴趣计算和检索。

**概率连乘树并不适用匹配问题**：

在有了使用层次化树结构来增加检索效率的思路后，首先尝试了概率连乘树的形式。这个形式在Natural Language Processing（自然语言处理）中已经有了一些工作和探讨（例如Hierarchical Softmax，Word2Vec等）。虽然最后不幸的发现，这个优美的概率形式并不能对匹配问题带来实质的帮助，但它对真正理清匹配问题的要点和难点从而提出真正可用的方法是很有帮助的。以Hierarchical Softmax（以下简称：HS）为例，每一个叶子节点（词）都有到根节点编码唯一的一条路径，而给定前置上文，下一个词出现的概率被建模为编码路径上分类概率的连乘。传统的多分类 Softmax 里归一化项依赖所有类别项的计算，所以即使计算一个类别的概率的计算量也很大，而通过概率连乘树的方式，HS 有效避免了在传统Softmax建模中需要遍历所有叶子节点计算分母归一化项的过程。假设我们通过类似 HS 的方式建立了叶子节点为商品的树，把上下文认为是用户输入，把输出的叶子节点概率认为是用户对商品的兴趣度，看上去 HS 可以解决我们的匹配问题。但经过我们的分析和实践，事实并非如此。

* HS方法解决了给定上文进行节点概率快速计算的问题，即通过引入Hierarchical Structure避免了对全量候选集的逐一计算和归一化，直接计算得到节点概率。但对于匹配和推荐TopK这类全局寻优问题 HS 并不适用，因为当给定用户输入时，寻找最优的TopK候选我们仍然需要遍历所有的叶子节点，计算各个叶子的连乘概率，对概率排序得到最优的K个。而任何贪心的检索方法如BeamSearch，都无法保证检索得到的TopK是全局最优的，即 HS 建模方式下每一层的最优连乘并不保证全局最优。所以需要遍历全部叶子计算的HS方法并不适合大规模候选集的匹配和推荐问题。

* 与此同时，HS 方法在建树时往往会考虑将某种具有相似关系（语义、词频等）的节点靠近组成兄弟。而 HS 方法在计算路径概率时把每一个节点的概率计算看作是二分类问题，用于判断接下来选择哪个孩子节点继续走下去。这种判断优与次优的分类方法对于HS是适用和有效的，但对于匹配和推荐问题却是无法成立的，因为当两个孩子具有某种相似关系时，用户往往是同时喜欢或者同时不喜欢。也就说在单层节点上，匹配和推荐要求的是该层上的全局序判别问题，而 HS 方法解决的是同一父亲下两个孩子节点谁更优的问题。

在采用 HS 方法进行匹配和推荐的实践中，包括YouTube团队在他们的内积模式向量检索做匹配的文章中提到了他们采用HS方法学习用户和候选Video的偏好关系，但是效果并不理想。值得一提的是，这样的树方法在算法和工程上都复杂度极高。这么一个大工程效果却不尽人如意使得整个项目组经历了最艰难的一段时间。我们根据BadCase对算法（主要是样本构成）做了很多调整，并最终调出了效果。可这些调整细节，使得算法和树概率形式理论不完全对应，一直是我们心中的隐忧。直到我们提出了新的树形式理论，不仅完美和有效方法对应，而且基于新理论我们建立了完整的树结构全库检索方法。

**最大堆树的提出和构建**：

推翻概率连乘树方法的思路，需要构建一套全新的方法体系来实现树结构的构建、基于树的训练采样和TopK检索、以及节点兴趣度计算的统一。回到匹配问题本身，假定全量候选集中的每一个商品都是一个叶子节点，当前用户对所有叶子节点背后都存在一个真实的兴趣度，用概率 $p_i(u)$ 表示。我们并不知道其具体值，只有根据概率采样出来的样本（用户真实反馈）。对于一般的模型，我们可以对叶子节点的概率建模，但是要找TopK需要遍历所有节点，计算量太大。因此我们创新性的提出了兴趣最大堆树（Max-heap like Tree）的概念，其定义树上节点的概率如下：

$$ p^{j}(n|u) = \frac{max_{n_c \in {n's children nodes in level j + 1}} p^{j+1}(n_c | u)}{\alpha^{j}} \tag{2}$$

即用户对第 $j$ 层父亲节点兴趣的偏好概率正比于用户对第 $j+1$ 层孩子节点兴趣的偏好概率最大值，其中 $\alpha(j)$ 是第 $j$ 层节点兴趣概率的归一化因子。根据最大堆树的定义，如果已知这棵树上的每层节点概率之间的序（同层内），我们可以快速找到全局TopK，即从根节点出发找当前层的TopK，然后在上层TopK节点对应的下层孩子节点集合中继续找TopK，递归向下直至叶子。但问题是这棵树上的节点概率我们现在并不知道，但是我们可以想办法得到符合树节点概率的序的样本，然后用深度学习在这个样本上进行拟合也即得到了节点概率之间的序。具体地，对于任意一个用户有行为的叶子节点采样 $i$，隐含了叶子层的序：$ p_i \gt p_j，for \quad all \quad i \neq j $。根据我们的树节点概率定义（最大堆性质），可以向上递归推出每层节点概率的序。根据这个序我们进行负样本采样，用深度学习模型基于这个采样去学习，以逼近最大堆树上每层的序。

