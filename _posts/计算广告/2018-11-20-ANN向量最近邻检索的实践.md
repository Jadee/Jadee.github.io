---
title: ANN向量最近邻检索的实践
date: 2018-11-20
categories: 计算广告
tags:
- 计算广告
- 广告触发
---

# 背景

向量化召回相比以前的召回方式，可以利用更为全面的信息，提高全流量的匹配精度，扩大长尾流量的召回深度，而向量最近邻检索是向量化召回的关键能力，对召回效果有非常重要的影响。

<!-- more -->

向量化召回模型的简要示意图如下：

![avatar](/images/trigger/trigger-18.png)

将用户请求信号通过左侧深度网络表达为一个向量 $q$，广告信息通过右侧深度网络表达为一个向量 $a$，然后用两者的向量距离（欧式/cos/內积）来表征广告点击率，$q$ 与 $a$ 的距离越近，则预估点击率越高。

在向量化召回系统中，向量最近邻检索是重要一环，其作用是：以尽可能高效的方式在广告向量库中检索出与请求向量 $q$ 距离最近的topK个广告。这些广告作为最具潜力的广告将被送入排序模块进行综合打分。

![avatar](/images/trigger/trigger-19.png)

如何在大规模向量库中快速地找到距离最近的topK向量集合？这个问题在学术界上被称为“最近邻检索”（Approximate Nearest Neighbor）。

基础的量化方法只能支持向量欧式距离，这大大限制了向量化召回的模型设计。为了支持更多的距离度量（cos/內积），通过在索引构建流程中集成了向量变换算法，从而解决了这一难题。此工作将在第三节“支持多种距离度量”中进行介绍。

另外，对于搜索广告的业务场景，有两大特色：一是系统中有数百万的广告主参与，据统计，淘宝直通车广告主每天增删广告12.1万次，修改广告31.5万次。广告主对广告的增删改操作需要在向量索引库中实时生效，这就要求我们的向量化引擎和最近邻检索算法具备支持实时更新的能力。二是广告召回阶段需要考虑RPM等业务指标，因此对于业务指标表现较好的广告，我们应该在最近似检索时给予更准确的距离度量。为了满足这两大业务需求，需要对标准的向量近邻检索进行优化升级，这将在第四节“支持在线加权量化”中进行介绍。

# 相关研究

随着深度学习的兴起，向量的最近邻检索在近些年获得了大量关注。目前，主流的ANN算法有四类：

## 基于树结构的方法

首先使用树结构（KD-tree/KMeans-tree等）对向量空间进行逐层切分，然后将query向量 $q$ 从根节点开始走一遍树结构，直到叶子节点。与 $q$ 同叶子节点的候选向量作为近邻向量被返回。如果单个叶子节点中的候选向量数量不够，则树方法还会进行回溯，从而召回更多邻近叶子的向量。

树方法的优势是原理简单，实现容易。缺点是在向量维度较大时（>10维）就将退化为线性搜索，效率与暴力差不多。

## 基于Hash的方法

Hash类的方法首先使用哈希函数将向量投射到一个向量桶中，理想的哈希函数能够将相近的向量投射到同一个向量桶中。近邻搜索时，仅在 $q$ 所在的向量桶及其邻近桶中进行查找，以此缩小了搜索范围，提高了搜索效率。

Hash类的方法本质上依然是对空间的切分，后面出现的图方法和量化方法都宣称获得了比Hash更好的效果。

## 基于图的方法

基于图的方法是最近几年刚刚出现的ANN分支，这类方法一般分为两步，第一步是构建近邻图，第二步是在近邻图中进行启发式搜索。

构建近邻图时，先将所有候选向量作为顶点，然后将每个顶点的近邻点都使用边连接起来。近邻点的求解可以使用暴力计算，也可以使用其他的一些改进算法，比如KD-tree。启发式搜索时，从近邻图的任意一点出发，将该点的近邻加入候选集合U，然后在U中与q进行比较，找到最近的一个点，再将该点的近邻加入集合U，重复上述步骤，直到U不再更新。

## 基于量化的方法

基于量化（Product Quantization，PQ）的方法把向量切割成多段子向量，然后分别在每段子向量空间中分别进行K-Means聚类，再将小向量用簇中心点代表，此即为“量化”。近邻搜索时，同样将请求向量q进行切割量化，然后用量化后的中心点之间的距离代替原始子向量之间的距离，这样便大大减少了距离计算。

如下图所示，子向量 $y$ 和子向量 $x$ 的距离可以用簇中心点 $q(y)$ 和 $q(x)$ 的距离代表，其中，$q(\cdot)$ 表示量化函数，它将子向量量化到中心点上。

![avatar](https://images2015.cnblogs.com/blog/1138886/201707/1138886-20170713170123493-1279483958.png)

原始向量之间的距离则是各自小向量的量化距离之和：

$$ \begin{align} d(X,Y) = L_2(X,Y) &= \sum_{i=1}^n L_2(x_i, y_i)  \\ 
& \approx \sum_{i=1}^n L_2(P(x_i), P(y_i))
\end{align}
$$

PQ有一些改进算法，最常见的就是IVFPQ。它是将量化过程分为两步，第一步先做粗量化，也就是用少量的中心点代表向量全集，这肯定会产生较多的残差。故还需再对残差向量进行分段量化，即“积量化”。若以 $q_c(\cdot)$ 表示粗量化，$q_p(\cdot)$ 表示积量化，则 $y$ 可表示为：

$$ y \approx q_c(y) + q_p(y - q_c(y))$$ 

故 $x$ 与 $y$ 的距离可表示为：

$$ \begin{align} d(X,Y) & \approx  d(x, q_c(y) + q_p(y - q_c(y))) \\
& = d(x - q_c(y), q_p(y - q_c(y)))
\end{align}
$$

由此易知，IVFPQ的查询过程：

* Step1: 找到与请求向量x最邻近的粗量化中心点，计算两者间的残差。

* Step2: 计算残差与积量化中心点之间的距离，将此距离作为x与候选向量y之间的距离。

* Step3: 返回最近邻粗量化簇中，距离在topK的向量。

IVFPQ的好处是进一步缩小了搜索集合，加快了查找效率。

量化方法以其简洁高效的优点迅速占领了各大公司的技术栈。Facebook在2017年3月开源了其内部项目FAISS（Facebook AI Similarity Search），正是一个标准的PQ索引构建库。

相比其他三种方法，PQ方法经历了更多工业界的检验，在相关报道中表现优异。在基于PQ进行向量最近邻检索的实践过程中，独特的业务需求驱动了对标准算法进行完善和改进，下文将就其中两点介绍我们的工作。

# 支持多种距离度量

Motivation: 向量化召回模型可能采用多种距离度量方式，包括：L2欧式距离、COS距离、內积等。然而，由于基于量化的方法是将子向量之间的距离加和得到整体距离，所以天然地只能支持L2距离。为了让向量化召回模型的设计不受距离度量方式的束缚，直通车的技术小二在向量近邻检索模块中集成了cos和內积的适配算法。

## COS距离

基于cos距离的向量化召回模型的范式如下简图：

![avatar](/images/trigger/trigger-20.png)

为了能将cos距离运用在量化方法中，我们需要将cos距离转化为L2距离。首先展开请求向量 $q$ 与广告向量 $a(a \in A)$ 之间的L2距离公式：

$$ L_2(q, a) = |q|^2 + |a|^2 - 2 * cos<q, a> $$

由于在一次检索中，请求向量 $q$ 是固定的，所以 $\| q \|$ 是定值，不影响偏序。我们可以对向量 $a$ 进行归一化：

$$ L_2(q, a_e) = C + 1 - 2 * cos<q, a_e> $$

可见 $cos<q, a_e>$ 与 $L_2(q, a_e)$ 正好是反向的线性相关关系。若设 $R_{asc}(x)$ 表示集合 $X$ 中元素 $x$ 之间的升序关系，$R_{des}(x)$ 表示降序关系，则有：

$$  R_{asc}(L_2(q, a_e))  =  R_{des}(cos<q, a_e>)$$

而我们知道，向量归一化后的单位向量是不改变夹角的，即：

$$ cos<q, a> = cos<q, a_e>$$

所以可得：

$$ R_{des}(cos<q, a>)  = R_{des}(cos<q, a_e>) = R_{asc}(L_2(q, a_e)) $$

根据上述理论的指导，我们在向量化检索模块中，先将广告向量进行归一化，然后再存入PQ的向量索引库。

在线检索时，通过PQ查找出与向量q的欧式距离最近的topK个广告（L2距离升序），这些广告也同样是与q的cos距离最近的广告（cos距离降序）。

整体的流程如下图：

![avatar](/images/trigger/trigger-21.png)

## 內积距离

基于內积的距离度量是另一类常见的向量化范型，比如在Youtube推荐系统的Candidate Generator阶段，使用了softmax的loss function，将video向量与用户向量进行了內积。直通车的向量化召回模型，也有使用到內积，其上面join层是logistics函数，输入是将广告向量和请求向量进行內积的值。內积大的，则认为预估其CTR高。基于內积的模型范式如下图：

![avatar](/images/trigger/trigger-22.png)

基于內积的向量化检索较为复杂，这甚至在ANN学术领域形成了一个专门的分支，叫Maximum Inner Product Search (MIPS)。近年来，诸多学者提出了自己的算法，例如2014年NIPS会议的最佳论文《Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)》及Google在AISTATS 2016发表的《Quantization based Fast Inner Product Search》都是为了解决这一难题。相比后者，ALSH提出的向量变换方法无需进行训练学习，效果也更好。

首先对候选广告向量a作如下幂转换：$a_{u} = \frac{a}{U}$，其中：$U = \mu*\operatorname{}{{max \|a\|}}, \\: \mu \gt 1$。则 $0 < \left \| a_{u} \right\| < 1 $。

然后对请求向量 $q$ 和 $a_u$ 进行扩展：

$$ \tilde{q} = \left\lbrack q;1/2;1/2;\ldots;1/2 \right\rbrack $$

$$ \tilde{a_{u}} = \left\lbrack a_{u};\left| a_{u} \right|^{2^{1}};\left| a_{u} \right|^{2^{2}};\ldots;\left| a_{u} \right|^{2^{m}} \right\rbrack $$

上式中，向量 $q$ 后扩展了 m 个 $\frac{1}{2}$。此时：

$${|\tilde{a_{u}}|}^{2} = \left| a_{u} \right|^{2} + \left| a_{u} \right|^{4} + \ldots + \left| a_{u} \right|^{2^{m + 1}} $$

$${|\tilde{q}|}^{2} = \left| q \right|^{2} + 1/4 + \ldots + 1/4 $$

$${\tilde{q}}^{T}\tilde{a_{u}} = q^{T}a_{u} + \frac{1}{2}(\left| a_{u} \right|^{2^{1}} + \left| a_{u} \right|^{2^{2}} + \ldots + \left| a_{u} \right|^{2^{m}}) $$

对于 $\tilde{q}$ 和 $\tilde{q}$ 的欧式距离：

$$ \begin{align} L_{2}\left( \tilde{q},\tilde{a_{u}} \right) &= {|\tilde{q}|}^{2} + {|\tilde{a_{u}}|}^{2} - 2*{\tilde{q}}^{T}\tilde{a_{u}} \\
& = \left| q \right|^{2} + \frac{m}{4} + \left( \left| a_{u} \right|^{2} + \left| a_{u} \right|^{4} + \ldots + \left| a_{u} \right|^{2^{m + 1}} \right) - 2*q^{T}a_{u} - \left( \left| a_{u} \right|^{2^{1}} + \left| a_{u} \right|^{2^{2}} + \ldots + \left| a_{u} \right|^{2^{m}} \right) \\
& = \left| q \right|^{2} + \frac{m}{4} + \left| a_{u} \right|^{2^{m + 1}} - 2*q^{T}a_{u}
\end{align}
$$

在单次请求中，$\|q\|$ 是定值，$\frac{m}{4}$ 也是算法设定值。而由于 $0 < \left \| a_{u} \right \| < 1$，所以有：

$$ \operatorname{}{(\left| a_{u} \right|^{2^{m + 1}})} = 0$$

进而得到：

$$ L_{2}\left( \tilde{q},\tilde{a_{u}} \right) = C - 2*q^{T}a_{u} $$

可见 $q$ 与 $a_u$ 的內积正好与 $\tilde{q}$ 与 $\tilde{a_u}$ 的L2距离是相反的线性关系。同时我们知道，对 $a$ 做幂转换不影响 $q$ 与 $a$ 內积的偏序关系。则有：

$$ R_{\text{des}}\left( q^{T}a \right)\  = R_{\text{des}}\left( q^{T}a_{u} \right) = R_{\text{asc}}(L_{2}\left( \tilde{q},\tilde{a_{u}} \right)) $$

至此，我们将 $q$ 与 $a$ 的內积关系映射为了 $\tilde{q}$ 与 $\tilde{a_u}$ 的L2距离。

在向量检索模块中，我们使用 $\tilde{a_u}$ 构建PQ索引库。在线查找时，首先将 $q$ 变换得到 $\tilde{q}$，然后在索引库中找到与其L2距离最近的topK个广告（L2距离升序），根据上述理论分析，这topK个广告就是与q的內积值最大的topK广告集（內积降序）。

流程图如下：

![avatar](/images/trigger/trigger-23.png)

# 支持在线加权量化

Motivation: 正如前文所述，在搜索广告的业务场景中，有两个特色区别于一般的近邻检索场景：一是需要实时支持广告主的增删改操作，二是要对业务指标表现较好的广告给予更准确的度量，减少它们的误差。不同于一般的索引库，PQ向量索引在构建过程中需要学习中心点的位置。因此，为了支持广告增删改的实时生效，需要设计PQ的在线学习算法。搜索直通车的技术小二为此设计了加权在线量化算法（weighted online product quantization），目前正在集成到向量检索模块中。

对于IVFPQ，可以写出其Loss function为：

$$ Loss = \sum_{i}^{}{p\left( x_{i} \right)*{\frac{1}{2}(x_{i} - w_{c}\left( x_{i} \right) - w_{q}(x_{i} - w_{c}\left( x_{i} \right)))}^{2}} $$

其中，$p(x_i)$ 为 $x_i$ 的权重，在我们的场景下可以是广告的PV量，也可以是CTR/CVR/RPM等。$w_c(x_i)$ 是 $x_i$ 粗量化的中心点，$w_q(\cdot)$ 是积量化的中心点。这里为了最小化loss，既可以迭代更新粗量化中心点，也可以迭代更新积量化中心点。但由于积量化是依赖于粗量化的，所以为了简化问题讨论，我们可以设定粗量化中心点固定不变，则Loss function可改写为：

$$ Loss = \sum_{i}^{}{p\left( x_{i} \right)*{\frac{1}{2}(r_{x_{i}} - w_{q}(r_{x_{i}}))}^{2}} $$

其中，$r_{x_i}$ 表示 $x_i$ 与最近的粗量化中心点之间的残差，即 $r_{x_i} = x_i - w_c(x_i)$。

在此，我们仅讨论如何处理广告新增即可，因为广告删除可被视为新增的逆向操作，而广告修改则被视为删除+新增的二步组合。

当新广告 $x_{n+1}$ 到来时，我们首先计算得到它的 $r_{x_{n+1}}$ 和 $w_q(r_{x_{n+1}})$，由于我们固定了粗量化中心点，所以 $r_{x_{n+1}}$ 固定不变，所在的积量化簇也随之被确定。此时，我们只需对该积量化簇的中心点进行位置更新，以使得loss变为极小值：

![avatar](/images/trigger/trigger-24.png)

其中，$\varepsilon$ 为学习率，$C$ 为 $r_{x_{n+1}}$ 所在的积量化簇。

特别地，假设 $p(x_i)$ 都等权重为1，且取学习率 $\varepsilon = \frac{1}{t},(t = 1,2,\ldots,n + 1)$，则此时：

$$ w_{q} = \frac{1}{n + 1}*\left( r_{x_{n + 1}} - w_{q}\left( r_{x_{n + 1}} \right) \right) $$

# 工程实现

总体架构如下图所示：

![avatar](/images/trigger/trigger-25.png)

Inference是为向量召回引擎设计的请求改写模块，其输入是用户的历史点击矩阵及与该请求相似的历史点击矩阵，这些点击矩阵会转发给一个称为Generating Service的服务，该服务会将点击矩阵利用深度学习网络生成一个多维的向量。这里的Generating Service底层使用的模型文件能被在线学习更新，并在新一轮离线训练之后被替换。

Vector Search目标在于找到与查询向量最相似的K个目标向量，这里基于Facebook的Faiss库进行深度定制开发。由于广告具有很强的类目属性，所以我们在离线构建的过程中，首先会将广告向量聚合成多个类目分区，并将每个分区构建成单独的索引文件。由于分区存在较大的不均衡性，有的分区仅仅有数百个广告，有的分区有数十万个，所以我们对不同的分区采取了不同索引类型。

为了支持动态更新，我们对Faiss内核进行了修改，采用了一种层级的索引结构（有点类似于LSM）以支持增量更新。

IndexBuilder会以一定周期产出全量索引，并推送上线并进行在线替换。IndexUpdater接受广告主变更消息，并对索引进行在线更新。IndexUpdater和IndexBuilder共享Generating Service提供的向量生成服务。

Generating Service是一个在线服务模块，其通过深度学习模型文件根据Ad的特征数据计算产出一个多维向量。这里的模型文件通过离线Training产生，并被Online Learning更新。

